{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real and fake news classification made by Alexandre Olivier and Cedric Viret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "- **0) Part Zero: Cleaning the data, creating and applying NTLK pre-processing methods of both title and text**\n",
    "<br>\n",
    "\n",
    "- **1) First Analysis: we analysed title and text separately and predict from both their in sample results using SGDClassifier**<br>\n",
    "\n",
    "- **2) Second Analysis: we combine title and text together**\n",
    "    - 2.1) Base Model1: Naïve Bayes\n",
    "    - 2.2) Base Model1: Logistic Regression\n",
    "    - 2.3) Stacking Methods: using SGDClassifier, PassiveAgressive and Linear SVM\n",
    "    <br>\n",
    "- **3) Third Analysis: Stemming on top of lemmatized combine features**\n",
    "    - 3.1) Stacking Methods: using SGDClassifier, PassiveAgressive and Linear SVM\n",
    "    - 3.2) Out of Sample prediction\n",
    "    - 3.3) Conclusion and improvement<br>\n",
    "- **4) Grid Search and Randomized Search: This section is not needed to understand our analysis (but important to find the best models and parameters)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "pd.set_option(\"max_columns\", None)\n",
    "\n",
    "import nltk\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier,PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"fake_or_real_news_training.csv\", sep=',')\n",
    "test = pd.read_csv(\"fake_or_real_news_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6903</td>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7341</td>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4869</td>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2909</td>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              title  \\\n",
       "0   8476                       You Can Smell Hillary’s Fear   \n",
       "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4    875   The Battle of New York: Why This Primary Matters   \n",
       "5   6903                                        Tehran, USA   \n",
       "6   7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "7     95                  ‘Britain’s Schindler’ Dies at 106   \n",
       "8   4869  Fact check: Trump and Clinton at the 'commande...   \n",
       "9   2909  Iran reportedly makes new push for uranium con...   \n",
       "\n",
       "                                                text label   X1   X2  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  NaN  NaN  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  NaN  NaN  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  NaN  NaN  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  NaN  NaN  \n",
       "4  It's primary day in New York and front-runners...  REAL  NaN  NaN  \n",
       "5    \\nI’m not an immigrant, but my grandparents ...  FAKE  NaN  NaN  \n",
       "6  Share This Baylee Luciani (left), Screenshot o...  FAKE  NaN  NaN  \n",
       "7  A Czech stockbroker who saved more than 650 Je...  REAL  NaN  NaN  \n",
       "8  Hillary Clinton and Donald Trump made some ina...  REAL  NaN  NaN  \n",
       "9  Iranian negotiators reportedly have made a las...  REAL  NaN  NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overview of the data\n",
    "train.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital training shape: (3999, 6)\n",
      "Inital test shape: (2321, 3)\n",
      "ID for train is unique and can be dropped\n",
      "ID for test is unique and can be dropped\n",
      "X1 cannot be dropped\n",
      "X2 cannot be dropped\n"
     ]
    }
   ],
   "source": [
    "print(\"Inital training shape:\",train.shape)\n",
    "print(\"Inital test shape:\",test.shape)\n",
    "\n",
    "#check unique id train and test\n",
    "if len(train.ID.unique())==train.shape[0]:\n",
    "    print(\"ID for train is unique and can be dropped\")\n",
    "else:\n",
    "    print(\"ID for train is NOT unique and cannot be dropped\")\n",
    "    \n",
    "#same for test\n",
    "if len(test.ID.unique())==test.shape[0]:\n",
    "    print(\"ID for test is unique and can be dropped\")\n",
    "else:\n",
    "    print(\"ID for test is NOT unique and cannot be dropped\")\n",
    "\n",
    "#checking X1 and X2\n",
    "for col in ['X1','X2']:\n",
    "    if len(train[train.loc[:,col].isnull()==True])==train.shape[0]:\n",
    "        print(col, 'can be dropped')\n",
    "    else:\n",
    "        print(col,\"cannot be dropped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking X1 and X2\n",
    "We noticed that when reading the files, some of the title,text and label data is pushed up to the last two columns. As such, we need to do some transformation in order to put everything back where it should be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two cases we needed to distinguish. \n",
    "First one is when the data is shifted in X1. In this case, we noticed that the full title is located in the title and the text column. The full text is hence located in the label column and the labels in the X1 column. Thus, we need to shift back the data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>599</td>\n",
       "      <td>Election Day: No Legal Pot In Ohio</td>\n",
       "      <td>Democrats Lose In The South</td>\n",
       "      <td>Election Day: No Legal Pot In Ohio; Democrats ...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>10194</td>\n",
       "      <td>Who rode it best? Jesse Jackson mounts up to f...</td>\n",
       "      <td>Leonardo DiCaprio to the rescue?</td>\n",
       "      <td>Who rode it best? Jesse Jackson mounts up to f...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>356</td>\n",
       "      <td>Black Hawk crashes off Florida</td>\n",
       "      <td>human remains found</td>\n",
       "      <td>(CNN) Thick fog forced authorities to suspend ...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>2786</td>\n",
       "      <td>Afghanistan: 19 die in air attacks on hospital</td>\n",
       "      <td>U.S. investigating</td>\n",
       "      <td>(CNN) Aerial bombardments blew apart a Doctors...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>3622</td>\n",
       "      <td>Al Qaeda rep says group directed Paris magazin...</td>\n",
       "      <td>US issues travel warning</td>\n",
       "      <td>A member of Al Qaeda's branch in Yemen said Fr...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                              title  \\\n",
       "192    599                 Election Day: No Legal Pot In Ohio   \n",
       "308  10194  Who rode it best? Jesse Jackson mounts up to f...   \n",
       "382    356                     Black Hawk crashes off Florida   \n",
       "660   2786     Afghanistan: 19 die in air attacks on hospital   \n",
       "889   3622  Al Qaeda rep says group directed Paris magazin...   \n",
       "\n",
       "                                  text  \\\n",
       "192        Democrats Lose In The South   \n",
       "308   Leonardo DiCaprio to the rescue?   \n",
       "382                human remains found   \n",
       "660                 U.S. investigating   \n",
       "889           US issues travel warning   \n",
       "\n",
       "                                                 label    X1   X2  \n",
       "192  Election Day: No Legal Pot In Ohio; Democrats ...  REAL  NaN  \n",
       "308  Who rode it best? Jesse Jackson mounts up to f...  FAKE  NaN  \n",
       "382  (CNN) Thick fog forced authorities to suspend ...  REAL  NaN  \n",
       "660  (CNN) Aerial bombardments blew apart a Doctors...  REAL  NaN  \n",
       "889  A member of Al Qaeda's branch in Yemen said Fr...  REAL  NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set a new df for the values that are not NAn for X1 or X2\n",
    "uncompleted_x1 = train[(train.X1.isnull()!=True) & (train.X2.isnull()==True)]\n",
    "uncompleted_x1.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of row changed 31\n"
     ]
    }
   ],
   "source": [
    "#replace missing values\n",
    "title = [col1 + col2 for col1,col2 in zip(uncompleted_x1.title, uncompleted_x1.text)] #concatenate the title and text together to get full title\n",
    "label = [lab for lab in uncompleted_x1.X1] #get the label\n",
    "text = [lab for lab in uncompleted_x1.label] #get the text\n",
    "\n",
    "for i,tit,tex,lab in  zip(uncompleted_x1.index.tolist(), title,text,label):\n",
    "     train.iloc[i,1], train.iloc[i,2],train.iloc[i,3] = tit,tex,lab\n",
    "        \n",
    "#check\n",
    "#for i in uncompleted_x1.index.tolist():\n",
    "#    print(i,len(train.iloc[i,1]), len(train.iloc[i,2]), len(train.iloc[i,3]), len(train.iloc[i,4]))\n",
    "    \n",
    "print('Amount of row changed',len(uncompleted_x1.index.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second case is when the data is pushed all the way to the last column X2. We identified only two such case and similarly as for the first case, we execute the same transformation. The difference here is that the full title is split across title, text and label, and the last two column contain the text and label respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>9</td>\n",
       "      <td>Planned Parenthood’s lobbying effort</td>\n",
       "      <td>pay raises for federal workers</td>\n",
       "      <td>and the future Fed rates</td>\n",
       "      <td>PLANNED PARENTHOOD’S LOBBYING GETS AGGRESSIVE....</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>6268</td>\n",
       "      <td>Chart Of The Day: Since 2009—–Recovery For The 5%</td>\n",
       "      <td>Stagnation for the 95%</td>\n",
       "      <td>Chart Of The Day: Since 2009 Recovery For The 5%</td>\n",
       "      <td>Stagnation for the 95%</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                              title  \\\n",
       "2184     9               Planned Parenthood’s lobbying effort   \n",
       "3537  6268  Chart Of The Day: Since 2009—–Recovery For The 5%   \n",
       "\n",
       "                                 text  \\\n",
       "2184   pay raises for federal workers   \n",
       "3537           Stagnation for the 95%   \n",
       "\n",
       "                                                 label  \\\n",
       "2184                          and the future Fed rates   \n",
       "3537  Chart Of The Day: Since 2009 Recovery For The 5%   \n",
       "\n",
       "                                                     X1    X2  \n",
       "2184  PLANNED PARENTHOOD’S LOBBYING GETS AGGRESSIVE....  REAL  \n",
       "3537                           Stagnation for the 95%    FAKE  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncompleted_x2 = train[train.X2.isnull()!=True]\n",
    "uncompleted_x2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uncompleted_x2 = train[train.X2.isnull()!=True]\n",
    "uncompleted_x2.head()\n",
    "\n",
    "title = [col1 + col2+ col3 for col1,col2,col3 in zip(uncompleted_x2.title, uncompleted_x2.text, uncompleted_x2.label)]\n",
    "\n",
    "#manual transformation\n",
    "train.iloc[2184,1] = title[0]\n",
    "train.iloc[2184,2] = train.iloc[2184,4]\n",
    "train.iloc[2184,3] = train.iloc[2184,5]\n",
    "\n",
    "train.iloc[3537,1] = title[1]\n",
    "train.iloc[3537,2] = train.iloc[3537,4]\n",
    "train.iloc[3537,3] = train.iloc[3537,5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>9</td>\n",
       "      <td>Planned Parenthood’s lobbying effort pay raise...</td>\n",
       "      <td>PLANNED PARENTHOOD’S LOBBYING GETS AGGRESSIVE....</td>\n",
       "      <td>REAL</td>\n",
       "      <td>PLANNED PARENTHOOD’S LOBBYING GETS AGGRESSIVE....</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>6268</td>\n",
       "      <td>Chart Of The Day: Since 2009—–Recovery For The...</td>\n",
       "      <td>Stagnation for the 95%</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Stagnation for the 95%</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                              title  \\\n",
       "2184     9  Planned Parenthood’s lobbying effort pay raise...   \n",
       "3537  6268  Chart Of The Day: Since 2009—–Recovery For The...   \n",
       "\n",
       "                                                   text label  \\\n",
       "2184  PLANNED PARENTHOOD’S LOBBYING GETS AGGRESSIVE....  REAL   \n",
       "3537                           Stagnation for the 95%    FAKE   \n",
       "\n",
       "                                                     X1    X2  \n",
       "2184  PLANNED PARENTHOOD’S LOBBYING GETS AGGRESSIVE....  REAL  \n",
       "3537                           Stagnation for the 95%    FAKE  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[uncompleted_x2.index.tolist(),:] # here we add back the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3966"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[train.loc[:,'X1'].isnull()==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999, 3)\n",
      "(2321, 2)\n"
     ]
    }
   ],
   "source": [
    "#drop X1 and X2\n",
    "train.drop([\"X1\",\"X2\"], inplace = True, axis = 1)\n",
    "\n",
    "#save train and test id\n",
    "train_id = train.ID\n",
    "test_id = test.ID\n",
    "\n",
    "#drop train and test id\n",
    "train.drop([\"ID\"], inplace = True, axis = 1)\n",
    "test.drop([\"ID\"], inplace = True, axis = 1)\n",
    "\n",
    "#print shape\n",
    "print(train.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understand target - balanced class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d4b367a470>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAFoCAYAAAB3+xGSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLSISMCpuEZGAUXGLiATM/wNxuiAeePWnPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d4b3684390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.groupby('label')['label'].count().plot.pie(figsize=(6,6), autopct='%.2f', legend=True, title=\"News' Type\",colormap =\"Paired\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is a binary classification problem:**\n",
    "Let's recode the FAKE/REAL label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target shape: (3999, 1) and features shape: (3999, 2)\n"
     ]
    }
   ],
   "source": [
    "#create traget\n",
    "y_train = pd.DataFrame(train.label.apply(lambda x: 1 if x == \"FAKE\" else 0), columns=['label'])\n",
    "\n",
    "#create features\n",
    "features = train.iloc[:,0:2]\n",
    "print(\"target shape:\",y_train.shape,\"and features shape:\",features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating function\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer,WordNetLemmatizer\n",
    "from nltk import pos_tag,DefaultTagger,RegexpTagger\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import pos_tag\n",
    "#CountVectorizer,RegexpStemmer,DefaultTagger\n",
    "\n",
    "import string\n",
    "\n",
    "#tokenized\n",
    "def word_tokenized(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "#stop word\n",
    "def stop_word(text, stopword,split):\n",
    "    if split is True:\n",
    "        text = [word for word in text.split() if word not in stopword]\n",
    "    else:\n",
    "        text = [word for word in text if word not in stopword]\n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "def stem(text, stem, split):\n",
    "    if split is True:\n",
    "        text = [stem.stem(word) for word in text.split()]\n",
    "    else:\n",
    "         text = [stem.stem(word) for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "#lemmatazing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def lem(text, split):\n",
    "    if split is True:\n",
    "        text = [WordNetLemmatizer().lemmatize(word) for word in text.split()]\n",
    "    else:\n",
    "         text = [WordNetLemmatizer().lemmatize(word) for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "#POS\n",
    "\n",
    "part = {\n",
    "    'N' : 'n',\n",
    "    'V' : 'v',\n",
    "    'J' : 'a',\n",
    "    'S' : 's',\n",
    "    'R' : 'r'\n",
    "}\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def convert_tag(penn_tag):\n",
    "    '''\n",
    "    convert_tag() accepts the **first letter** of a Penn part-of-speech tag,\n",
    "    then uses a dict lookup to convert it to the appropriate WordNet tag.\n",
    "    '''\n",
    "    if penn_tag in part.keys():\n",
    "        return part[penn_tag]\n",
    "    else:\n",
    "        # other parts of speech will be tagged as nouns\n",
    "        return 'n'\n",
    "    \n",
    "def tag_and_lem(element, tokenized):\n",
    "    '''\n",
    "    tag_and_lem() accepts a string, tokenizes, tags, converts tags,\n",
    "    lemmatizes, and returns a string\n",
    "    '''\n",
    "    # list of tuples [('token', 'tag'), ('token2', 'tag2')...]\n",
    "    \n",
    "    if tokenized is True:\n",
    "        sent = pos_tag((element)) # must tag in context\n",
    "        return ' '.join([wnl.lemmatize(sent[k][0], convert_tag(sent[k][1][0]))\n",
    "                    for k in range(len(sent))])\n",
    "    else:\n",
    "        sent = pos_tag(word_tokenize(element)) # must tag in context\n",
    "        return ' '.join([wnl.lemmatize(sent[k][0], convert_tag(sent[k][1][0]))\n",
    "                    for k in range(len(sent))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### NLTK Methodolgy<br>\n",
    "We applied different NLTK text processing methods from simple tokenization to lemmatizing on both title and text columns - we saved each individual transformation as a new feature of the dataset. <br>\n",
    "**Our assumption was that to find a good model title and text might required different NLTK processing**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focusing on Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenized title in lower case\n",
    "features['t0'] = features.title.apply(lambda x: word_tokenized(x.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 smell hillary ’ fear\n",
       "1    watch exact moment paul ryan committed politic...\n",
       "Name: t0t1, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#stopword with punctionation lower\n",
    "stopwords = stopwords.words('english')\n",
    "features['t0t1']=features.t0.apply(lambda x: stop_word(x, stopwords,False))\n",
    "\n",
    "features.t0t1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 smell hillary ’ fear\n",
       "1    watch exact moment paul ryan committed politic...\n",
       "Name: t0t2, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#stopword with punctionation lower\n",
    "stopwords = stopwords.words('english')+ list(string.punctuation)\n",
    "features['t0t2']=features.t0.apply(lambda x: stop_word(x, stopwords,False))\n",
    "\n",
    "features.t0t2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part of Speech (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#POS\n",
    "pos_title = features.t0.apply(lambda x: pos_tag(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('watch', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('exact', 'JJ'),\n",
       " ('moment', 'NN'),\n",
       " ('paul', 'NN'),\n",
       " ('ryan', 'NN'),\n",
       " ('committed', 'VBD'),\n",
       " ('political', 'JJ'),\n",
       " ('suicide', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('trump', 'NN'),\n",
       " ('rally', 'NN'),\n",
       " ('(', '('),\n",
       " ('video', 'NN'),\n",
       " (')', ')')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_title[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Lemmatizing with POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lem = features.t0.apply(lambda x: tag_and_lem(x,True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch the exact moment paul ryan commit political suicide at a trump rally ( video )'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that that it is functionning because \"committed\" has been transformed to \"commit\"** <br>\n",
    "\n",
    "So far, we only have made 3 transformations:\n",
    "-\tTokenized the text\n",
    "-\tTokenized the text and remove the stop word\n",
    "-\tTokenized the text and remove the stop including the punctuation\n",
    "<br>\n",
    "\n",
    "The next step is to apply Stemming on Lemmatizing on the above listed transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming and Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower case\n",
      "0                       you can smell hillary ’ s fear\n",
      "1    watch the exact moment paul ryan commit politi...\n",
      "Name: t0t3, dtype: object\n",
      "0                       you can smell hillari ’ s fear\n",
      "1    watch the exact moment paul ryan commit polit ...\n",
      "Name: t0t4, dtype: object\n",
      "0                                 smell hillary ’ fear\n",
      "1    watch exact moment paul ryan commit political ...\n",
      "Name: t0t1t3, dtype: object\n",
      "0                                 smell hillary ’ fear\n",
      "1    watch exact moment paul ryan commit political ...\n",
      "Name: t0t1t3, dtype: object\n",
      "0                                 smell hillary ’ fear\n",
      "1    watch exact moment paul ryan commit political ...\n",
      "Name: t0t2t3, dtype: object\n",
      "0                                 smell hillary ’ fear\n",
      "1    watch exact moment paul ryan commit political ...\n",
      "Name: t0t2t3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#set two different stemmer\n",
    "PS = PorterStemmer()\n",
    "#SS = SnowballStemmer('english')\n",
    "\n",
    "##### LOWER CASE TOKENIZER\n",
    "#stemming on tockenized data\n",
    "features['t0t3'] = features.t0.apply(lambda x: tag_and_lem(x,True))\n",
    "features['t0t4'] = features.t0.apply(lambda x: stem(x,PS, False))\n",
    "\n",
    "#stemining on tockenized data + word stop\n",
    "features['t0t1t3'] = features.t0t1.apply(lambda x: tag_and_lem(x,False))\n",
    "features['t0t1t4'] = features.t0t1.apply(lambda x: stem(x,PS, True))\n",
    "\n",
    "#stemining on tockenized data + word stop + ponctuation stop\n",
    "features['t0t2t3'] = features.t0t2.apply(lambda x: tag_and_lem(x,False))\n",
    "features['t0t2t4'] = features.t0t2.apply(lambda x: stem(x,PS, True))\n",
    "\n",
    "\n",
    "print(\"lower case\")\n",
    "print(features.t0t3.head(2))\n",
    "print(features.t0t4.head(2))\n",
    "print(features.t0t1t3.head(2))\n",
    "print(features.t0t1t3.head(2))\n",
    "print(features.t0t2t3.head(2))\n",
    "print(features.t0t2t3.head(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focusing on Text<br>\n",
    "We applied the same NLTK transfromations made on the title to the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenized text in lower case\n",
    "features['tt0'] = features.text.apply(lambda x: word_tokenized(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    daniel greenfield , shillman journalism fellow...\n",
       "1    google pinterest digg linkedin reddit stumbleu...\n",
       "Name: tt0tt1, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "#stopword + lower case\n",
    "stopwords = stopwords.words('english')\n",
    "features['tt0tt1']=features.tt0.apply(lambda x: stop_word(x,stopwords,False))\n",
    "features.tt0tt1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    daniel greenfield shillman journalism fellow f...\n",
       "1    google pinterest digg linkedin reddit stumbleu...\n",
       "Name: tt0tt2, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#stopword with punctionation lower case\n",
    "stopwords = stopwords.words('english')+ list(string.punctuation)\n",
    "features['tt0tt2']=features.tt0.apply(lambda x: stop_word(x, stopwords,False))\n",
    "\n",
    "features.tt0tt2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    daniel greenfield , a shillman journalism fell...\n",
      "1    google pinterest digg linkedin reddit stumbleu...\n",
      "Name: tt0tt3, dtype: object\n",
      "0    daniel greenfield , a shillman journal fellow ...\n",
      "1    googl pinterest digg linkedin reddit stumbleup...\n",
      "Name: tt0tt4, dtype: object\n",
      "0    daniel greenfield , shillman journalism fellow...\n",
      "1    google pinterest digg linkedin reddit stumbleu...\n",
      "Name: tt0tt1tt3, dtype: object\n",
      "0    daniel greenfield , shillman journalism fellow...\n",
      "1    google pinterest digg linkedin reddit stumbleu...\n",
      "Name: tt0tt1tt3, dtype: object\n",
      "0    daniel greenfield shillman journalism fellow f...\n",
      "1    google pinterest digg linkedin reddit stumbleu...\n",
      "Name: tt0tt2tt3, dtype: object\n",
      "0    daniel greenfield shillman journalism fellow f...\n",
      "1    google pinterest digg linkedin reddit stumbleu...\n",
      "Name: tt0tt2tt3, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### LOWER CASE TOKENIZER\n",
    "#stemming on tockenized data\n",
    "features['tt0tt3'] = features.tt0.apply(lambda x: tag_and_lem(x,True))\n",
    "gc.collect()\n",
    "features['tt0tt4'] = features.tt0.apply(lambda x: stem(x,PS, False))\n",
    "print(features.tt0tt3.head(2))\n",
    "print(features.tt0tt4.head(2))\n",
    "gc.collect()\n",
    "\n",
    "#stemining on tockenized data + word stop\n",
    "features['tt0tt1tt3'] = features.tt0tt1.apply(lambda x: tag_and_lem(x,False))\n",
    "gc.collect()\n",
    "features['tt0tt1tt4'] = features.tt0tt1.apply(lambda x: stem(x,PS, True))\n",
    "gc.collect()\n",
    "\n",
    "print(features.tt0tt1tt3.head(2))\n",
    "print(features.tt0tt1tt3.head(2))\n",
    "\n",
    "#stemining on tockenized data + word stop + ponctuation stop\n",
    "features['tt0tt2tt3'] = features.tt0tt2.apply(lambda x: tag_and_lem(x,False))\n",
    "gc.collect()\n",
    "\n",
    "features['tt0tt2tt4'] = features.tt0tt2.apply(lambda x: stem(x,PS, True))\n",
    "gc.collect()\n",
    "\n",
    "print(features.tt0tt2tt3.head(2))\n",
    "print(features.tt0tt2tt3.head(2))\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#copy features\n",
    "features_c = features.copy()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View of all the features<br>\n",
    "list of NLTK transformation we applied on the title and text (total 9 NLTK transformation).\n",
    "\n",
    "- simple tokenization\n",
    "- tokenization with remove stop words\n",
    "- tokenization with remove stop words and the punctuation\n",
    "- lemmatizing on simple tokenization \n",
    "- stemming on simple tokenization \n",
    "- lemmatizing on tokenization with remove stop words\n",
    "- stemming on tokenization with remove stop words\n",
    "- lemmatizing on tokenization with remove stop words and the punctuation\n",
    "- stemming on tokenization with remove stop words and the punctuation\n",
    "\n",
    "** “t” features correspond to transformation applied on title and “tt” correspond to transformation apply on the text. So the encoding for title would be something like: tXtXtX and for title: ttXttXttX with X corresponding to a number. More details below: **\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>t0</th>\n",
       "      <th>t0t1</th>\n",
       "      <th>t0t2</th>\n",
       "      <th>t0t3</th>\n",
       "      <th>t0t4</th>\n",
       "      <th>t0t1t3</th>\n",
       "      <th>t0t1t4</th>\n",
       "      <th>t0t2t3</th>\n",
       "      <th>t0t2t4</th>\n",
       "      <th>tt0</th>\n",
       "      <th>tt0tt1</th>\n",
       "      <th>tt0tt2</th>\n",
       "      <th>tt0tt3</th>\n",
       "      <th>tt0tt4</th>\n",
       "      <th>tt0tt1tt3</th>\n",
       "      <th>tt0tt1tt4</th>\n",
       "      <th>tt0tt2tt3</th>\n",
       "      <th>tt0tt2tt4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>[you, can, smell, hillary, ’, s, fear]</td>\n",
       "      <td>smell hillary ’ fear</td>\n",
       "      <td>smell hillary ’ fear</td>\n",
       "      <td>you can smell hillary ’ s fear</td>\n",
       "      <td>you can smell hillari ’ s fear</td>\n",
       "      <td>smell hillary ’ fear</td>\n",
       "      <td>smell hillari ’ fear</td>\n",
       "      <td>smell hillary ’ fear</td>\n",
       "      <td>smell hillari ’ fear</td>\n",
       "      <td>[daniel, greenfield, ,, a, shillman, journalis...</td>\n",
       "      <td>daniel greenfield , shillman journalism fellow...</td>\n",
       "      <td>daniel greenfield shillman journalism fellow f...</td>\n",
       "      <td>daniel greenfield , a shillman journalism fell...</td>\n",
       "      <td>daniel greenfield , a shillman journal fellow ...</td>\n",
       "      <td>daniel greenfield , shillman journalism fellow...</td>\n",
       "      <td>daniel greenfield , shillman journal fellow fr...</td>\n",
       "      <td>daniel greenfield shillman journalism fellow f...</td>\n",
       "      <td>daniel greenfield shillman journal fellow free...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  \\\n",
       "0  You Can Smell Hillary’s Fear   \n",
       "\n",
       "                                                text  \\\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...   \n",
       "\n",
       "                                       t0                  t0t1  \\\n",
       "0  [you, can, smell, hillary, ’, s, fear]  smell hillary ’ fear   \n",
       "\n",
       "                   t0t2                            t0t3  \\\n",
       "0  smell hillary ’ fear  you can smell hillary ’ s fear   \n",
       "\n",
       "                             t0t4                t0t1t3                t0t1t4  \\\n",
       "0  you can smell hillari ’ s fear  smell hillary ’ fear  smell hillari ’ fear   \n",
       "\n",
       "                 t0t2t3                t0t2t4  \\\n",
       "0  smell hillary ’ fear  smell hillari ’ fear   \n",
       "\n",
       "                                                 tt0  \\\n",
       "0  [daniel, greenfield, ,, a, shillman, journalis...   \n",
       "\n",
       "                                              tt0tt1  \\\n",
       "0  daniel greenfield , shillman journalism fellow...   \n",
       "\n",
       "                                              tt0tt2  \\\n",
       "0  daniel greenfield shillman journalism fellow f...   \n",
       "\n",
       "                                              tt0tt3  \\\n",
       "0  daniel greenfield , a shillman journalism fell...   \n",
       "\n",
       "                                              tt0tt4  \\\n",
       "0  daniel greenfield , a shillman journal fellow ...   \n",
       "\n",
       "                                           tt0tt1tt3  \\\n",
       "0  daniel greenfield , shillman journalism fellow...   \n",
       "\n",
       "                                           tt0tt1tt4  \\\n",
       "0  daniel greenfield , shillman journal fellow fr...   \n",
       "\n",
       "                                           tt0tt2tt3  \\\n",
       "0  daniel greenfield shillman journalism fellow f...   \n",
       "\n",
       "                                           tt0tt2tt4  \n",
       "0  daniel greenfield shillman journal fellow free...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "features.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have applied all NLTK preprocessing transformation we can get rid of the initial columns (title and text) they are not useful for the rest of our analysis and modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the title\n",
    "remove_col = ['title','text'] #remove initial data\n",
    "features.drop(remove_col, axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['t0', 't0t1', 't0t2', 't0t3', 't0t4', 't0t1t3', 't0t1t4', 't0t2t3',\n",
       "       't0t2t4', 'tt0', 'tt0tt1', 'tt0tt2', 'tt0tt3', 'tt0tt4', 'tt0tt1tt3',\n",
       "       'tt0tt1tt4', 'tt0tt2tt3', 'tt0tt2tt4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999, 18)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting the title and text columns\n",
    "title = features.iloc[:,:9].columns\n",
    "text = features.iloc[:,9:].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Changing t0 and tt0 type to string\n",
    "features['t0'] = str(features['t0'])\n",
    "features['tt0'] = str(features['tt0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## First Analysis <br>\n",
    "\n",
    "We analysed separately the text and title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Focusing on Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kfold strategy\n",
    "kfold = KFold(n_splits=3,random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done: ['t0']\n",
      "loading done: ['t0', 't0t1']\n",
      "loading done: ['t0', 't0t1', 't0t2']\n",
      "loading done: ['t0', 't0t1', 't0t2', 't0t3']\n",
      "loading done: ['t0', 't0t1', 't0t2', 't0t3', 't0t4']\n",
      "loading done: ['t0', 't0t1', 't0t2', 't0t3', 't0t4', 't0t1t3']\n",
      "loading done: ['t0', 't0t1', 't0t2', 't0t3', 't0t4', 't0t1t3', 't0t1t4']\n",
      "loading done: ['t0', 't0t1', 't0t2', 't0t3', 't0t4', 't0t1t3', 't0t1t4', 't0t2t3']\n",
      "loading done: ['t0', 't0t1', 't0t2', 't0t3', 't0t4', 't0t1t3', 't0t1t4', 't0t2t3', 't0t2t4']\n"
     ]
    }
   ],
   "source": [
    "model, score, para = [],{},{}\n",
    "\n",
    "#final_grid = GridSearchCV(final_pipe, para, scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=10, pre_dispatch='2*n_jobs')\n",
    "if __name__ == \"__main__\":\n",
    "    for i in title:\n",
    "        #Create a pipeline\n",
    "        final_pipe = Pipeline([('vc', CountVectorizer()),\n",
    "                          ('tt', TfidfTransformer()),\n",
    "                          ('SDG', SGDClassifier())])\n",
    "\n",
    "        #Set parameters\n",
    "        para = {'vc__ngram_range': ((1, 1), (1, 2)), \n",
    "        'tt__use_idf': (True, False),\n",
    "        }\n",
    "\n",
    "        #Randomized\n",
    "        final_grid = GridSearchCV(final_pipe, para ,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=0, pre_dispatch='2*n_jobs')\n",
    "        final_grid.fit(features.loc[:,i],y_train.values)\n",
    "        \n",
    "       \n",
    "        #Append\n",
    "        model.append(i)\n",
    "        score[i] = final_grid.best_score_ \n",
    "        para[i] = final_grid.best_params_\n",
    "        print(\"loading done: {}\".format(model))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t0t2t3</th>\n",
       "      <td>0.804451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0t2t4</th>\n",
       "      <td>0.802951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0t4</th>\n",
       "      <td>0.801450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0t3</th>\n",
       "      <td>0.801200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0t1t4</th>\n",
       "      <td>0.800950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0t2</th>\n",
       "      <td>0.800450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0t1t3</th>\n",
       "      <td>0.799450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0t1</th>\n",
       "      <td>0.794449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0</th>\n",
       "      <td>0.511378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           score\n",
       "t0t2t3  0.804451\n",
       "t0t2t4  0.802951\n",
       "t0t4    0.801450\n",
       "t0t3    0.801200\n",
       "t0t1t4  0.800950\n",
       "t0t2    0.800450\n",
       "t0t1t3  0.799450\n",
       "t0t1    0.794449\n",
       "t0      0.511378"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the model score\n",
    "score_title = pd.DataFrame.from_dict({'score':score})\n",
    "score_title.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Focusing on text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done: ['tt0']\n",
      "loading done: ['tt0', 'tt0tt1']\n",
      "loading done: ['tt0', 'tt0tt1', 'tt0tt2']\n",
      "loading done: ['tt0', 'tt0tt1', 'tt0tt2', 'tt0tt3']\n",
      "loading done: ['tt0', 'tt0tt1', 'tt0tt2', 'tt0tt3', 'tt0tt4']\n",
      "loading done: ['tt0', 'tt0tt1', 'tt0tt2', 'tt0tt3', 'tt0tt4', 'tt0tt1tt3']\n",
      "loading done: ['tt0', 'tt0tt1', 'tt0tt2', 'tt0tt3', 'tt0tt4', 'tt0tt1tt3', 'tt0tt1tt4']\n",
      "loading done: ['tt0', 'tt0tt1', 'tt0tt2', 'tt0tt3', 'tt0tt4', 'tt0tt1tt3', 'tt0tt1tt4', 'tt0tt2tt3']\n",
      "loading done: ['tt0', 'tt0tt1', 'tt0tt2', 'tt0tt3', 'tt0tt4', 'tt0tt1tt3', 'tt0tt1tt4', 'tt0tt2tt3', 'tt0tt2tt4']\n"
     ]
    }
   ],
   "source": [
    "model, score, para = [],{},{}\n",
    "\n",
    "#final_grid = GridSearchCV(final_pipe, para, scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=10, pre_dispatch='2*n_jobs')\n",
    "if __name__ == \"__main__\":\n",
    "    for i in text:\n",
    "        #Create a pipeline\n",
    "        final_pipe = Pipeline([('vc', CountVectorizer()),\n",
    "                          ('tt', TfidfTransformer()),\n",
    "                          ('SDG', SGDClassifier())])\n",
    "\n",
    "        #Set parameters\n",
    "        para = {'vc__ngram_range': ((1, 1), (1, 2)), \n",
    "        'tt__use_idf': (True, False),\n",
    "        }\n",
    "\n",
    "        #Randomized\n",
    "        final_grid = GridSearchCV(final_pipe, para ,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=0, pre_dispatch='2*n_jobs')\n",
    "        final_grid.fit(features.loc[:,i],y_train.values)\n",
    "        \n",
    "       \n",
    "        #Append\n",
    "        model.append(i)\n",
    "        score[i] = final_grid.best_score_ \n",
    "        para[i] = final_grid.best_params_\n",
    "        print(\"loading done: {}\".format(model))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tt0tt4</th>\n",
       "      <td>0.929232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0tt3</th>\n",
       "      <td>0.928732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0tt1tt4</th>\n",
       "      <td>0.926482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0tt1tt3</th>\n",
       "      <td>0.925981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0tt2</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0tt2tt3</th>\n",
       "      <td>0.925231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0tt2tt4</th>\n",
       "      <td>0.923481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0tt1</th>\n",
       "      <td>0.922231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0</th>\n",
       "      <td>0.511378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score\n",
       "tt0tt4     0.929232\n",
       "tt0tt3     0.928732\n",
       "tt0tt1tt4  0.926482\n",
       "tt0tt1tt3  0.925981\n",
       "tt0tt2     0.925481\n",
       "tt0tt2tt3  0.925231\n",
       "tt0tt2tt4  0.923481\n",
       "tt0tt1     0.922231\n",
       "tt0        0.511378"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the model score\n",
    "score_text = pd.DataFrame.from_dict({'score':score})\n",
    "score_text.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First conclusion<br>\n",
    "When analysed separately the text has more predictive power that title. The best model for **text** has an accuracy score of around **92.9%**, while **title** best accuracy score is only at **80%**.<br>\n",
    "It is even more interesting to see that NLTK pipeline provide a different best score for different features:\n",
    "-  Simple tokenization without stop words gives the best results for text (tt0tt4)\n",
    "-  Stemming on tokenization without stop words and punctuation gives best results for title (t0t2t3) <br>\n",
    "\n",
    "<br>**With that data insight we decided to continue further our analysis be grouping the text and title together.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining title and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['t0', 't0t1', 't0t2', 't0t3', 't0t4', 't0t1t3', 't0t1t4', 't0t2t3',\n",
       "       't0t2t4', 'tt0', 'tt0tt1', 'tt0tt2', 'tt0tt3', 'tt0tt4', 'tt0tt1tt3',\n",
       "       'tt0tt1tt4', 'tt0tt2tt3', 'tt0tt2tt4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['t0t1', 't0t2', 't0t3', 't0t4', 't0t1t3', 't0t1t4', 't0t2t3', 't0t2t4'], dtype='object')\n",
      "Index(['tt0tt1', 'tt0tt2', 'tt0tt3', 'tt0tt4', 'tt0tt1tt3', 'tt0tt1tt4',\n",
      "       'tt0tt2tt3', 'tt0tt2tt4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "title_rework = title.drop('t0')\n",
    "text_reword = text.drop('tt0')\n",
    "print(title_rework)\n",
    "print(text_reword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed columns ‘t0’ and ‘tt0’ (simple tokenization) because they are not relevant for the rest of our analysis - independently these transformations scored the lower for both title and text (around 50%).\n",
    "\n",
    "<br>\n",
    "**As we already discovered on the first analysis, title and text might need different NLTK processing to find best results possible… Therefore, we decided to combine all the NLTK transformation for the title and text together. Hence, we end up with: 64 possible combinations of title and text (8 different NLTK transformations on title * 8 different NLTK transformations on text). **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining title and text together\n",
    "combine2 = [features[[i,j]].apply(lambda x: ' '.join(x), axis = 1) for i in title_rework for j in text_reword]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combine2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the best NLTK pre-processing methods in our 64 possible combinations of title and text we ran a grid search with grid parameters:\n",
    "**-unigram, bigram and trigram** for **“count vectorizer” ** and **“TFIDF transform” **\n",
    "**We apply this grid search with algorithms (Logistic Regression, SGDclassifier, PassiveAgressiveClassifier and Linear SVM)**\n",
    "\n",
    "The results of the analysis can be find on section “Ad hoc” at the end of this notebook:\n",
    "\n",
    "<br>\n",
    "**How to understand the matrix**: t01 and tt0tt1 are the same NLTK pre-processing apply on title (t0) and text (tt0), corresponding to NLTK transformation: tokenized without stops word. So “M0” in the matrix refers to the above-mentioned transformation.<br>\n",
    "Applying that logic we have, for instance, “M31” equal to the title feature lemmatized on tokenized words and the text features stemmed with tokenized words without stop words and punctuation.\n",
    "\n",
    "In the below image you can find  all the models combinations – we highlighted the top3 score for each algorithm\n",
    "\n",
    "<img src=\"Final_matrix.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a pattern in the columns “tt0tt3 ” and “tt0tt4” which correspond to lemmatizing on **simple tokenization and stemming on simple tokenization for the text**.\n",
    "While for the **title** there is a clear pattern related to the “t0t2t3” transformation which correspond to **lemmatizing on tokenization without stop words and punctuation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering on best NLTK pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the insights we get from the previous steps we decided to narrow down our possible combination of features. We only considered the best 3 results of the 2 models with the highest first score (PassiveAgressive and SDGClassifier). See the below image: <br>\n",
    "\n",
    "<img src=\"Final_top3.png\">\n",
    "\n",
    "\n",
    "**Hence, reducing NLTK pre-processing combination from 64 to only 6. These 6 combinations will be used for our base model.**<br>\n",
    "\n",
    "<br>Note: the score difference between the 4 algorithms top 3 (as showed on the above image) was minimal (max difference of 1%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting the best NLTK pre-preocessing\n",
    "filter_models = []\n",
    "for i in [27,53,35,26,3,50]:     #best model score \n",
    "    filter_models.append(combine2[i])\n",
    "    gc.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model 1: Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0]\n",
      "loading done:for model: [0, 1]\n",
      "loading done:for model: [0, 1, 2]\n",
      "loading done:for model: [0, 1, 2, 3]\n",
      "loading done:for model: [0, 1, 2, 3, 4]\n",
      "loading done:for model: [0, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "model, score,vc, tf = [],{},{},{}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(0,len(filter_models)):\n",
    "\n",
    "        final_pipe = Pipeline([('vc', CountVectorizer()),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('ML', MultinomialNB())])\n",
    "        #Set parameters\n",
    "        para = {'vc__ngram_range': ((1, 1), (1, 2)), \n",
    "        'tt__use_idf': (True, False)\n",
    "        \n",
    "        }\n",
    "\n",
    "        #Randomized\n",
    "        base_grid = GridSearchCV(final_pipe,para,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=0, pre_dispatch='2*n_jobs')\n",
    "        base_grid.fit(filter_models[i],y_train.values)\n",
    "        \n",
    "         #Append\n",
    "        model.append(i)\n",
    "        score[i] = base_grid.best_score_\n",
    "        vc[i] = (base_grid.best_params_['vc__ngram_range'])\n",
    "        tf[i] = (base_grid.best_params_['tt__use_idf'])\n",
    "       \n",
    "        print(\"loading done:for model: {}\".format(model))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>VC</th>\n",
       "      <th>TF</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.819955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.778195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.777694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.775694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.763691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.762691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model      VC     TF     Score\n",
       "1      1  (1, 1)  False  0.819955\n",
       "0      0  (1, 1)  False  0.778195\n",
       "2      2  (1, 1)  False  0.777694\n",
       "4      4  (1, 1)  False  0.775694\n",
       "5      5  (1, 1)   True  0.763691\n",
       "3      3  (1, 1)   True  0.762691"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = pd.concat([pd.DataFrame(pd.Series(model, name = \"Model\")),\n",
    "                        pd.DataFrame(pd.Series(vc,name = 'VC')),\n",
    "                          pd.DataFrame(pd.Series(tf,name = 'TF')),\n",
    "                         pd.DataFrame(pd.Series(score,name = 'Score'))],axis = 1)\n",
    "\n",
    "#df\n",
    "base_model.sort_values('Score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model 2: Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0]\n",
      "loading done:for model: [0, 1]\n",
      "loading done:for model: [0, 1, 2]\n",
      "loading done:for model: [0, 1, 2, 3]\n",
      "loading done:for model: [0, 1, 2, 3, 4]\n",
      "loading done:for model: [0, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "model, score,vc, tf = [],{},{},{}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(0,len(filter_models)):\n",
    "\n",
    "        final_pipe = Pipeline([('vc', CountVectorizer()),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('ML', LogisticRegression())])\n",
    "        #Set parameters\n",
    "        para = {'vc__ngram_range': ((1, 1), (1, 2)), \n",
    "        'tt__use_idf': (True, False)\n",
    "        \n",
    "        }\n",
    "\n",
    "        #Randomized\n",
    "        base_grid = GridSearchCV(final_pipe,para,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=0, pre_dispatch='2*n_jobs')\n",
    "        base_grid.fit(filter_models[i],y_train.values)\n",
    "        \n",
    "         #Append\n",
    "        model.append(i)\n",
    "        score[i] = base_grid.best_score_\n",
    "        vc[i] = (base_grid.best_params_['vc__ngram_range'])\n",
    "        tf[i] = (base_grid.best_params_['tt__use_idf'])\n",
    "       \n",
    "        print(\"loading done:for model: {}\".format(model))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>VC</th>\n",
       "      <th>TF</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.905226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.902726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.902476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.902476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.902226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.900725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model      VC    TF     Score\n",
       "1      1  (1, 2)  True  0.905226\n",
       "2      2  (1, 1)  True  0.902726\n",
       "0      0  (1, 1)  True  0.902476\n",
       "3      3  (1, 1)  True  0.902476\n",
       "5      5  (1, 1)  True  0.902226\n",
       "4      4  (1, 1)  True  0.900725"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model2 = pd.concat([pd.DataFrame(pd.Series(model, name = \"Model\")),\n",
    "                        pd.DataFrame(pd.Series(vc,name = 'VC')),\n",
    "                          pd.DataFrame(pd.Series(tf,name = 'TF')),\n",
    "                         pd.DataFrame(pd.Series(score,name = 'Score'))],axis = 1)\n",
    "\n",
    "#df\n",
    "base_model2.sort_values('Score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily see that the best logistic regression (90%) outperformed the Naïve Bayes model (82%) – But logistic regression best score is lower that SDGClassifier score when performed only on Title (90% vs 92%). This lead to the conclusion that we should use different algorithms to increase our In-Sample score.<br>\n",
    "\n",
    "**After running a grid search on our 6 remaining possible combinations of NLTK pre-processing on text and title, we decided to select M27 which correspond to apply stemming on simple tokenization for both title and text (for details see further down in the notebook Extreme Grid Search section) .**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final model\n",
    "X_train = filter_models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: filter_models[0] equal to M27 in the 64 possible combination of NLTK transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Model: Voting classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our element ensemble: Stacking (Voting Classifier)  with used PassiveAgressive, SGDClassifier and Linear SVM (we discarded Logistic Regression and Naive Bayes because none of them get a score higher of 92%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.932983245811453 PA\n",
      "Accuracy: 0.9294823705926482 SDG\n",
      "Accuracy: 0.9344836209052264 LSVM\n",
      "Accuracy: 0.9342335583895974 Ensemble\n"
     ]
    }
   ],
   "source": [
    "#Create model Framework\n",
    "cf1 = Pipeline([('vc', CountVectorizer(ngram_range=(1,2))),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('PA', PassiveAggressiveClassifier(C=150))])\n",
    "\n",
    "cf2 = Pipeline([('vc', CountVectorizer(ngram_range=(1,2))),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('SGD', SGDClassifier(penalty='elasticnet'))])\n",
    "\n",
    "cf3 = Pipeline([('vc', CountVectorizer(ngram_range=(1,2))),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('LSVM', LinearSVC(C=300))])\n",
    "\n",
    "#list of estimator with names\n",
    "estimators = [('PA', cf1),('SGD', cf2),('LSVM', cf3)]\n",
    "\n",
    "#Voting Classifier\n",
    "ecf = VotingClassifier(estimators= estimators,\n",
    "                          voting='hard',            \n",
    "                          weights=None,\n",
    "                          n_jobs=1,\n",
    "                          flatten_transform=None)\n",
    "\n",
    "#Display Voting Classifier score\n",
    "for clf, label in zip([cf1, cf2,cf3, ecf], ['PA', 'SDG', 'LSVM', 'Ensemble']):\n",
    "       scores = cross_val_score(clf, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "       print(\"Accuracy: {} {}\".format(scores.mean(), label))\n",
    "#Voting Classifier fit\n",
    "#vc = ecf.fit(X_train, y_train)\n",
    "\n",
    "#Voting Classifier predict\n",
    "#vc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Voting Classifier fit\n",
    "vc = ecf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second conclusion\n",
    "Applying voting classifier (element ensemble) increase our score from 92% to 93.5%. Let ‘see if we can improve our score with a last analysis requiring NLTK pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M50 correspond to lemmatizing on tokenization with remove stop words and the punctuation for the title and lemmatizing on simple tokenization for the text. <br>** Thus, we can apply some Stemming methods on top of lemmatized features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch exact moment paul ryan commit political suicide trump rally video google pinterest digg linkedin reddit stumbleupon print delicious pocket tumblr there be two fundamental truth in this world : paul ryan desperately want to be president . and paul ryan will never be president . today prove it . in a particularly staggering example of political cowardice , paul ryan re-re-re-reversed course and announce that he be back on the trump train afte'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting M50 from filter_model\n",
    "m50 = filter_models[5]\n",
    "\n",
    "#glimpse at M50\n",
    "m50[1][:450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m50_stem = m50.apply(lambda x: stem(x,PS,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch exact moment paul ryan commit polit suicid trump ralli video googl pinterest digg linkedin reddit stumbleupon print delici pocket tumblr there be two fundament truth in thi world : paul ryan desper want to be presid . and paul ryan will never be presid . today prove it . in a particularli stagger exampl of polit cowardic , paul ryan re-re-re-revers cours and announc that he be back on the trump train after all . thi be an aboutfac from wher'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m50_stem[1][:450]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming on top of lemmatized works as expected, we have “president” that become “presid”.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3999"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len check\n",
    "len(m50_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gird search\n",
    "apply grid search to fnd the best paramters per algorthim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed: 10.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vc', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_a...='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'vc__ngram_range': ((1, 1), (1, 2), (1, 3)), 'tt__use_idf': (True, False), 'SGD__penalty': ('l2', 'l1', 'elasticnet')},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipe = Pipeline([('vc', CountVectorizer()),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('SGD', SGDClassifier())])\n",
    "#Set parameters\n",
    "para = {'vc__ngram_range': ((1, 1), (1, 2),(1,3)), \n",
    "'tt__use_idf': (True, False),\n",
    "'SGD__penalty':('l2','l1','elasticnet')\n",
    "\n",
    "}\n",
    "\n",
    "#Randomized\n",
    "base_grid = GridSearchCV(final_pipe,para,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=10, pre_dispatch='2*n_jobs')\n",
    "base_grid.fit(m50_stem,y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.929982495624\n",
      "{'SGD__penalty': 'l2', 'tt__use_idf': True, 'vc__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(base_grid.best_score_)\n",
    "print(base_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PassiveAgressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   38.0s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=2)]: Done  57 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=2)]: Done  68 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=2)]: Done  72 out of  72 | elapsed: 13.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vc', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_a...   n_jobs=1, random_state=None, shuffle=True, tol=None,\n",
       "              verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'vc__ngram_range': ((1, 1), (1, 2), (1, 3)), 'tt__use_idf': (True, False), 'PA__C': (0.1, 0.8, 2, 5)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipe = Pipeline([('vc', CountVectorizer()),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('PA', PassiveAggressiveClassifier())])\n",
    "#Set parameters\n",
    "para = {'vc__ngram_range': ((1, 1), (1, 2),(1,3)), \n",
    "'tt__use_idf': (True, False),\n",
    "'PA__C':(.1,.8,2,5)\n",
    "\n",
    "}\n",
    "\n",
    "#Randomized\n",
    "base_grid = GridSearchCV(final_pipe,para,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=10, pre_dispatch='2*n_jobs')\n",
    "base_grid.fit(m50_stem,y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.934483620905\n",
      "{'PA__C': 2, 'tt__use_idf': True, 'vc__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(base_grid.best_score_)\n",
    "print(base_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=2)]: Done  48 out of  48 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vc', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_a...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'vc__ngram_range': ((1, 1), (1, 2)), 'tt__use_idf': (True, False), 'SVM__C': (0.5, 1, 2, 5)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipe = Pipeline([('vc', CountVectorizer()),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('SVM', LinearSVC())])\n",
    "#Set parameters\n",
    "para = {'vc__ngram_range': ((1, 1), (1, 2)), \n",
    "'tt__use_idf': (True, False),\n",
    "'SVM__C':(.5,1,2,5),\n",
    "#'SVM__penality':('l2','l1')\n",
    "\n",
    "}\n",
    "\n",
    "#Randomized\n",
    "base_grid = GridSearchCV(final_pipe,para,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=10, pre_dispatch='2*n_jobs')\n",
    "base_grid.fit(m50_stem,y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935233808452\n",
      "{'SVM__C': 5, 'tt__use_idf': True, 'vc__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(base_grid.best_score_)\n",
    "print(base_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Model2: Voting classifier\n",
    "Apply voting classifier for the stemmed and lemmatized features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.935233808452113 PA\n",
      "Accuracy: 0.9329832458114528 SDG\n",
      "Accuracy: 0.9324831207801951 LSVM\n",
      "Accuracy: 0.9344836209052264 Ensemble\n"
     ]
    }
   ],
   "source": [
    "#Create model Framework\n",
    "cf12 = Pipeline([('vc', CountVectorizer(ngram_range=(1,2))),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('PA', PassiveAggressiveClassifier(C=2))])\n",
    "\n",
    "cf22 = Pipeline([('vc', CountVectorizer(ngram_range=(1,2))),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('SGD', SGDClassifier(penalty='l2'))])\n",
    "\n",
    "cf32 = Pipeline([('vc', CountVectorizer(ngram_range=(1,2))),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('LSVM', LinearSVC(C=5))])\n",
    "\n",
    "#list of estimator with names\n",
    "estimators = [('PA', cf1),('SGD', cf2),('LSVM', cf3)]\n",
    "\n",
    "#Voting Classifier\n",
    "ecf2 = VotingClassifier(estimators= estimators,\n",
    "                          voting='hard',            \n",
    "                          weights=None,\n",
    "                          n_jobs=1,\n",
    "                          flatten_transform=None)\n",
    "\n",
    "#Display Voting Classifier score\n",
    "for clf, label in zip([cf12, cf22,cf32, ecf2], ['PA', 'SDG', 'LSVM', 'Ensemble']):\n",
    "       scores = cross_val_score(ecf2, m50_stem, y_train, cv=kfold, scoring='accuracy')\n",
    "       print(\"Accuracy: {} {}\".format(scores.mean(), label))\n",
    "#Voting Classifier fit\n",
    "#vc = ecf.fit(X_train, y_train)\n",
    "\n",
    "#Voting Classifier predict\n",
    "#vc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Voting Classifier fit 2\n",
    "vc2 = ecf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third conclusion\n",
    "\n",
    "Strangely, applying a stemming method on top of lemmatized features did not improve our score <br>\n",
    "\n",
    "** For our submission, we decided to use the voting classifier of the third analysis. The main reason is that we only apply a cross validation technique with 3 folds (1333 row per fold) which most probably is no preventing enough overfitting (1). Thus, applying a more generalized approach we might have a better Out of Sample result. **\n",
    "<br>\n",
    "\n",
    "(1)\tBecause we made 64 possible combinations of title and text we needed to have a cross validation strategy that would converge \"fast\" (the number of fold influences the amount of time an algorithm takes to converge).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply best NLTK transformation on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#on titile\n",
    "from nltk.corpus import stopwords\n",
    "#stopword with punctionation lower\n",
    "stopwords = stopwords.words('english')+ list(string.punctuation)\n",
    "\n",
    "test['title_t'] = test.title.apply(lambda x: stem(tag_and_lem(stop_word(word_tokenized(x.lower()),stopwords,False),False),PS,True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#in text\n",
    "test['text_t'] =  test.text.apply(lambda x: stem(tag_and_lem(word_tokenized(x.lower()),True),PS,True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>title_t</th>\n",
       "      <th>text_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>September New Homes Sales Rise——-Back To 1992 ...</td>\n",
       "      <td>September New Homes Sales Rise Back To 1992 Le...</td>\n",
       "      <td>septemb new home sale rise——-back 1992 level</td>\n",
       "      <td>septemb new home sale rise back to 1992 level ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why The Obamacare Doomsday Cult Can't Admit It...</td>\n",
       "      <td>But when Congress debated and passed the Patie...</td>\n",
       "      <td>obamacar doomsday cult ca n't admit 's wrong</td>\n",
       "      <td>but when congress debat and pass the patient p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  September New Homes Sales Rise——-Back To 1992 ...   \n",
       "1  Why The Obamacare Doomsday Cult Can't Admit It...   \n",
       "\n",
       "                                                text  \\\n",
       "0  September New Homes Sales Rise Back To 1992 Le...   \n",
       "1  But when Congress debated and passed the Patie...   \n",
       "\n",
       "                                        title_t  \\\n",
       "0  septemb new home sale rise——-back 1992 level   \n",
       "1  obamacar doomsday cult ca n't admit 's wrong   \n",
       "\n",
       "                                              text_t  \n",
       "0  septemb new home sale rise back to 1992 level ...  \n",
       "1  but when congress debat and pass the patient p...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overview\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine title and text for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test[['title_t','text_t']].apply(lambda x: ' '.join(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"obamacar doomsday cult ca n't admit 's wrong but when congress debat and pass the patient protect and afford care act in 2009 and 2010 , oppon be nearli unifi in offer grim keech-lik predict . with obamacar now in full effect , and the economi on a decid upsw , the dour prognost be start to look like keech 's fli saucer . at least if you believ the data . a look at festing 's theori , though , can explain whi that wo n't matter , and whi american can expect a continu drumbeat of doom , even a the propheci fail . “ it certainli have not have the bale effect the critic be predict , ” say paul van de water , a senior fellow at the center on budget and polici prioriti who support the law , but never think it would have much econom impact . “ on balanc it may be a modest plu , to the extent that it have contribut to the slowdown of growth in health care costs. ” but that 's not how capitol hill ’ s gloomsday cult see it . inde , tri get ani of them to admit the afford care act job slaughter have not happen , and they sound like the punchlin to the old joke where a spous get catch in the act cheat : “ who be you go to believ -- me , or your lie eye ? ” '' with politician , you can ’ t be sure that what come out of their mouth be realli what ’ s in their head , '' say elliot aronson , one of festing ’ s former student who be regard a the foremost expert on cognit disson aliv today . `` when it come to polit , we have to realli look close . '' the way cognit disson work be that when peopl be confront with inform that contradict either their belief or action , they feel discomfort . to feel well , they either have to modifi their belief and action , or find some way to discount the disconfirm inform . and the more effort someon invest in a particular action or idea , the great the length they will go in craft justif to eas their discomfort . aronson and co-author carol tavri look close at that phenomenon in their 2007 book , mistak be make ( but not by me ) . among the exampl be prosecutor who insist that peopl clear by dna evid be still guilti ; scientist who insist result that agre with funder ’ interest could not have be sway , and peopl who like an idea from their polit parti , but dislik the same idea if tell it come from the opposit parti . inde , commit to a specif ideolog can make it much hard to see fact clearli , let alon acknowledg them . aronson note that it ’ s especi hard for peopl who spend the last five year oppos a specif polici . “ these guy be so commit to the belief that obama can ’ t do anyth right , and that obamacar be social , that it would be veri , veri difficult for them to examin the data object , '' he say . `` i think that ’ s what ’ s wrong with polit , that ’ s what ’ s wrong with ideolog , that ’ s what ’ s wrong with polit that be ideolog driven. ” “ one could creat some line of argument that the economi would be much , much strong without the aca , but that realli seem to be a stretch , ” say van de water , the economist . “ we have a veri larg economi . even as import a the afford care act be , it ’ s work on a major sector of the economi , but onli at the margin . even in advanc , one would have think it wasn ’ t go to have a huge effect . ”\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making sure that the combine title and testare correct\n",
    "X_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming on top of lemmatization worked, in the second line there is:  “economi…decid”**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Out of Sample prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = vc2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change the binary prediction to real or fake\n",
    "prediction = [\"FAKE\" if x == 1  else \"REAL\" for x in pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no misplace values\n"
     ]
    }
   ],
   "source": [
    "#check\n",
    "\n",
    "for i,j in zip(pred,prediction):\n",
    "    if i == 1 and j == \"FAKE\" or i == 0 and j == \"REAL\":\n",
    "        a = \"no misplace values\"\n",
    "    else:\n",
    "        a = \"MISPLACED VALUES\"\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test lenght:  2321\n",
      "prediction lenght:  2321\n"
     ]
    }
   ],
   "source": [
    "#last check before submitting\n",
    "print('test lenght: ',test.shape[0])\n",
    "print('prediction lenght: ',len(prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FAKE', 'REAL'], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['test_id'] = test_id\n",
    "submission['label'] = prediction\n",
    "\n",
    "#check if label are named properly\n",
    "\n",
    "submission.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10498</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2439</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id label\n",
       "0    10498  FAKE\n",
       "1     2439  REAL"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"Submission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The NLTK pre-processing that we finally selected was applying some stemming on:\n",
    "- lemmatization of tokenized title without stop words and punctuations\n",
    "- lemmatization of tokenized text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Potential improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We used « standard » stopword and punctuation, we could have added to this list our own stopword and punctuation. This might have an impact on the score.<br>\n",
    "\n",
    "In addition, our score would have been most probably better with Deep learning algorithms (Convolutional or LSTM Neural Network technic); but our aim was to play with NLTK pre-processing methods and see the impact of each method with “traditional” machine learning algorithms, such as Naïve Bayes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below selections are only including code for the girdsearch – it is not useful for understand our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDGClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed:  9.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0]\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1]\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2]\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed:  9.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2, 3]\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed:  9.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2, 3, 4]\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed:  9.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "model, score,vc, tf,tun = [],{},{},{},{}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(0,len(filter_models)):\n",
    "\n",
    "        final_pipe = Pipeline([('vc', CountVectorizer()),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('SGD', SGDClassifier())])\n",
    "        #Set parameters\n",
    "        para = {'vc__ngram_range': ((1, 1), (1, 2),(1,3)), \n",
    "        'tt__use_idf': (True, False),\n",
    "        'SGD__penalty':('l2','l1','elasticnet')\n",
    "        \n",
    "        }\n",
    "\n",
    "        #Randomized\n",
    "        base_grid = GridSearchCV(final_pipe,para,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=10, pre_dispatch='2*n_jobs')\n",
    "        base_grid.fit(filter_models[i],y_train.values)\n",
    "        \n",
    "         #Append\n",
    "        model.append(i)\n",
    "        score[i] = base_grid.best_score_\n",
    "        vc[i] = (base_grid.best_params_['vc__ngram_range'])\n",
    "        tf[i] = (base_grid.best_params_['tt__use_idf'])\n",
    "        tun[i] = (base_grid.best_params_['SGD__penalty'])\n",
    "       \n",
    "        print(\"loading done:for model: {}\".format(model))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>VC</th>\n",
       "      <th>TF</th>\n",
       "      <th>BP</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.932483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.931233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.931233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.930733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.930733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.928982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model      VC    TF          BP     Score\n",
       "0      0  (1, 2)  True  elasticnet  0.932483\n",
       "1      1  (1, 2)  True          l2  0.931233\n",
       "3      3  (1, 2)  True          l2  0.931233\n",
       "2      2  (1, 2)  True  elasticnet  0.930733\n",
       "4      4  (1, 2)  True          l2  0.930733\n",
       "5      5  (1, 2)  True          l2  0.928982"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdg_models = pd.concat([pd.DataFrame(pd.Series(model, name = \"Model\")),\n",
    "                        pd.DataFrame(pd.Series(vc,name = 'VC')),\n",
    "                        pd.DataFrame(pd.Series(tf,name = 'TF')),\n",
    "                        pd.DataFrame(pd.Series(tun,name = 'BP')),\n",
    "                        pd.DataFrame(pd.Series(score,name = 'Score'))],axis = 1)\n",
    "\n",
    "#df\n",
    "sdg_models.sort_values('Score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PassiveAgressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed: 10.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0]\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1]\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2]\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed: 10.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2, 3]\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed: 10.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2, 3, 4]\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed: 10.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "model, score,vc, tf,tun = [],{},{},{},{}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(0,len(filter_models)):\n",
    "\n",
    "        final_pipe = Pipeline([('vc', CountVectorizer()),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('PA', PassiveAggressiveClassifier())])\n",
    "        #Set parameters\n",
    "        para = {'vc__ngram_range': ((1, 1), (1, 2),(1,3)), \n",
    "        'tt__use_idf': (True, False),\n",
    "        'PA__C':(0.1,.4,.8)\n",
    "        \n",
    "        }\n",
    "\n",
    "        #Randomized\n",
    "        base_grid = GridSearchCV(final_pipe,para,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=10, pre_dispatch='2*n_jobs')\n",
    "        base_grid.fit(filter_models[i],y_train.values)\n",
    "        \n",
    "         #Append\n",
    "        model.append(i)\n",
    "        score[i] = base_grid.best_score_\n",
    "        vc[i] = (base_grid.best_params_['vc__ngram_range'])\n",
    "        tf[i] = (base_grid.best_params_['tt__use_idf'])\n",
    "        tun[i] = (base_grid.best_params_['PA__C'])\n",
    "       \n",
    "        print(\"loading done:for model: {}\".format(model))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>VC</th>\n",
       "      <th>TF</th>\n",
       "      <th>BP</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.936234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.935984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.934234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.933983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.933983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model      VC    TF   BP     Score\n",
       "2      2  (1, 2)  True  0.4  0.936234\n",
       "0      0  (1, 2)  True  0.8  0.935984\n",
       "4      4  (1, 2)  True  0.4  0.935484\n",
       "5      5  (1, 2)  True  0.4  0.934234\n",
       "1      1  (1, 2)  True  0.4  0.933983\n",
       "3      3  (1, 2)  True  0.8  0.933983"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_models = pd.concat([pd.DataFrame(pd.Series(model, name = \"Model\")),\n",
    "                        pd.DataFrame(pd.Series(vc,name = 'VC')),\n",
    "                        pd.DataFrame(pd.Series(tf,name = 'TF')),\n",
    "                        pd.DataFrame(pd.Series(tun,name = 'BP')),\n",
    "                        pd.DataFrame(pd.Series(score,name = 'Score'))],axis = 1)\n",
    "\n",
    "#df\n",
    "pa_models.sort_values('Score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done  15 out of  15 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0]\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=2)]: Done  15 out of  15 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1]\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=2)]: Done  15 out of  15 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2]\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done  15 out of  15 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2, 3]\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=2)]: Done  15 out of  15 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2, 3, 4]\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   58.1s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done  15 out of  15 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "#second search\n",
    "model, score,vc, tf,tun = [],{},{},{},{}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(0,len(filter_models)):\n",
    "\n",
    "        final_pipe = Pipeline([('vc', CountVectorizer(ngram_range=(1,2))),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('PA', PassiveAggressiveClassifier())])\n",
    "        #Set parameters\n",
    "        para = {\n",
    "        'PA__C':(50,100,150,300,500)\n",
    "        \n",
    "        }\n",
    "\n",
    "        #Randomized\n",
    "        base_grid = GridSearchCV(final_pipe,para,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=10, pre_dispatch='2*n_jobs')\n",
    "        base_grid.fit(filter_models[i],y_train.values)\n",
    "        \n",
    "         #Append\n",
    "        model.append(i)\n",
    "        score[i] = base_grid.best_score_\n",
    "        tun[i] = (base_grid.best_params_['PA__C'])\n",
    "       \n",
    "        print(\"loading done:for model: {}\".format(model))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.935734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.935234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.934984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.934984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.933983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.933983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model     Score\n",
       "0      0  0.935734\n",
       "2      2  0.935234\n",
       "1      1  0.934984\n",
       "4      4  0.934984\n",
       "3      3  0.933983\n",
       "5      5  0.933983"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa2_models = pd.concat([pd.DataFrame(pd.Series(model, name = \"Model\")),\n",
    "                        pd.DataFrame(pd.Series(score,name = 'Score'))],axis = 1)\n",
    "\n",
    "#df\n",
    "pa2_models.sort_values('Score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=2)]: Done  48 out of  48 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0]\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:   40.9s\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=2)]: Done  48 out of  48 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1]\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=2)]: Done  48 out of  48 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2]\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=2)]: Done  48 out of  48 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2, 3]\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=2)]: Done  48 out of  48 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2, 3, 4]\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:   58.5s\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=2)]: Done  48 out of  48 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "model, score,vc, tf,tun, tun1 = [],{},{},{},{},{}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(0,len(filter_models)):\n",
    "\n",
    "        final_pipe = Pipeline([('vc', CountVectorizer()),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('SVM', LinearSVC())])\n",
    "        #Set parameters\n",
    "        para = {'vc__ngram_range': ((1, 1), (1, 2)), \n",
    "        'tt__use_idf': (True, False),\n",
    "        'SVM__C':(.5,1,2,5),\n",
    "        #'SVM__penality':('l2','l1')\n",
    "        \n",
    "        }\n",
    "\n",
    "        #Randomized\n",
    "        base_grid = GridSearchCV(final_pipe,para,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=10, pre_dispatch='2*n_jobs')\n",
    "        base_grid.fit(filter_models[i],y_train.values)\n",
    "        \n",
    "         #Append\n",
    "        model.append(i)\n",
    "        score[i] = base_grid.best_score_\n",
    "        vc[i] = (base_grid.best_params_['vc__ngram_range'])\n",
    "        tf[i] = (base_grid.best_params_['tt__use_idf'])\n",
    "        tun[i] = (base_grid.best_params_['SVM__C'])\n",
    "       # tun2[i] = (base_grid.best_params_['SVM_penality'])\n",
    "       \n",
    "        print(\"loading done:for model: {}\".format(model))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>VC</th>\n",
       "      <th>TF</th>\n",
       "      <th>BP</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.934234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.933733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.933483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.932233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.932233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.930733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model      VC    TF  BP     Score\n",
       "0      0  (1, 2)  True   5  0.934234\n",
       "2      2  (1, 2)  True   5  0.933733\n",
       "4      4  (1, 2)  True   5  0.933483\n",
       "3      3  (1, 2)  True   5  0.932233\n",
       "5      5  (1, 2)  True   2  0.932233\n",
       "1      1  (1, 2)  True   5  0.930733"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_models = pd.concat([pd.DataFrame(pd.Series(model, name = \"Model\")),\n",
    "                        pd.DataFrame(pd.Series(vc,name = 'VC')),\n",
    "                        pd.DataFrame(pd.Series(tf,name = 'TF')),\n",
    "                        pd.DataFrame(pd.Series(tun,name = 'BP')),\n",
    "                        pd.DataFrame(pd.Series(score,name = 'Score'))],axis = 1)\n",
    "\n",
    "#df\n",
    "svm_models.sort_values('Score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   50.7s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=2)]: Done  15 out of  15 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0]\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=2)]: Done  15 out of  15 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1]\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=2)]: Done  15 out of  15 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2]\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=2)]: Done  15 out of  15 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2, 3]\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   55.7s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=2)]: Done  15 out of  15 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2, 3, 4]\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=2)]: Done  15 out of  15 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done:for model: [0, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "#second search\n",
    "model, score,vc, tf,tun = [],{},{},{},{}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(0,len(filter_models)):\n",
    "\n",
    "        final_pipe = Pipeline([('vc', CountVectorizer(ngram_range=(1,2))),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('SVM',  LinearSVC())])\n",
    "        #Set parameters\n",
    "        para = {\n",
    "        'SVM__C':(50,100,150,300,500)\n",
    "        \n",
    "        }\n",
    "\n",
    "        #Randomized\n",
    "        base_grid = GridSearchCV(final_pipe,para,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=10, pre_dispatch='2*n_jobs')\n",
    "        base_grid.fit(filter_models[i],y_train.values)\n",
    "        \n",
    "         #Append\n",
    "        model.append(i)\n",
    "        score[i] = base_grid.best_score_\n",
    "        tun[i] = (base_grid.best_params_['SVM__C'])\n",
    "       \n",
    "        print(\"loading done:for model: {}\".format(model))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.934734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.933483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.932983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.932483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.932483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.931983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model     Score\n",
       "0      0  0.934734\n",
       "2      2  0.933483\n",
       "4      4  0.932983\n",
       "3      3  0.932483\n",
       "5      5  0.932483\n",
       "1      1  0.931983"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_models2 = pd.concat([pd.DataFrame(pd.Series(model, name = \"Model\")),\n",
    "                        pd.DataFrame(pd.Series(score,name = 'Score'))],axis = 1)\n",
    "\n",
    "#df\n",
    "svm_models2.sort_values('Score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   41.6s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=2)]: Done  15 out of  15 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vc', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_a...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'SVM__C': (50, 100, 150, 300, 500)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipe = Pipeline([('vc', CountVectorizer(ngram_range=(1,2))),\n",
    "                                  ('tt', TfidfTransformer()),\n",
    "                                  ('SVM',  LinearSVC())])\n",
    "#Set parameters\n",
    "para = {\n",
    "'SVM__C':(50,100,150,300,500)\n",
    "\n",
    "}\n",
    "\n",
    "#Randomized\n",
    "base_grid = GridSearchCV(final_pipe,para,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=10, pre_dispatch='2*n_jobs')\n",
    "base_grid.fit(filter_models[0],y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ad hoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done: 0.0 for model: 0\n",
      "loading done: 1.5625 for model: 1\n",
      "loading done: 3.125 for model: 2\n",
      "loading done: 4.6875 for model: 3\n",
      "loading done: 6.25 for model: 4\n",
      "loading done: 7.8125 for model: 5\n",
      "loading done: 9.375 for model: 6\n",
      "loading done: 10.9375 for model: 7\n",
      "loading done: 12.5 for model: 8\n",
      "loading done: 14.0625 for model: 9\n",
      "loading done: 15.625 for model: 10\n",
      "loading done: 17.1875 for model: 11\n",
      "loading done: 18.75 for model: 12\n",
      "loading done: 20.3125 for model: 13\n",
      "loading done: 21.875 for model: 14\n",
      "loading done: 23.4375 for model: 15\n",
      "loading done: 25.0 for model: 16\n",
      "loading done: 26.5625 for model: 17\n",
      "loading done: 28.125 for model: 18\n",
      "loading done: 29.6875 for model: 19\n",
      "loading done: 31.25 for model: 20\n",
      "loading done: 32.8125 for model: 21\n",
      "loading done: 34.375 for model: 22\n",
      "loading done: 35.9375 for model: 23\n",
      "loading done: 37.5 for model: 24\n",
      "loading done: 39.0625 for model: 25\n",
      "loading done: 40.625 for model: 26\n",
      "loading done: 42.1875 for model: 27\n",
      "loading done: 43.75 for model: 28\n",
      "loading done: 45.3125 for model: 29\n",
      "loading done: 46.875 for model: 30\n",
      "loading done: 48.4375 for model: 31\n",
      "loading done: 50.0 for model: 32\n",
      "loading done: 51.5625 for model: 33\n",
      "loading done: 53.125 for model: 34\n",
      "loading done: 54.6875 for model: 35\n",
      "loading done: 56.25 for model: 36\n",
      "loading done: 57.8125 for model: 37\n",
      "loading done: 59.375 for model: 38\n",
      "loading done: 60.9375 for model: 39\n",
      "loading done: 62.5 for model: 40\n",
      "loading done: 64.0625 for model: 41\n",
      "loading done: 65.625 for model: 42\n",
      "loading done: 67.1875 for model: 43\n",
      "loading done: 68.75 for model: 44\n",
      "loading done: 70.3125 for model: 45\n",
      "loading done: 71.875 for model: 46\n",
      "loading done: 73.4375 for model: 47\n",
      "loading done: 75.0 for model: 48\n",
      "loading done: 76.5625 for model: 49\n",
      "loading done: 78.125 for model: 50\n",
      "loading done: 79.6875 for model: 51\n",
      "loading done: 81.25 for model: 52\n",
      "loading done: 82.8125 for model: 53\n",
      "loading done: 84.375 for model: 54\n",
      "loading done: 85.9375 for model: 55\n",
      "loading done: 87.5 for model: 56\n",
      "loading done: 89.0625 for model: 57\n",
      "loading done: 90.625 for model: 58\n",
      "loading done: 92.1875 for model: 59\n",
      "loading done: 93.75 for model: 60\n",
      "loading done: 95.3125 for model: 61\n",
      "loading done: 96.875 for model: 62\n",
      "loading done: 98.4375 for model: 63\n"
     ]
    }
   ],
   "source": [
    "model, score, para = [],{},{}\n",
    "\n",
    "#final_grid = GridSearchCV(final_pipe, para, scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=10, pre_dispatch='2*n_jobs')\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(0,len(combine2)):\n",
    "        #Create a pipeline\n",
    "        final_pipe = Pipeline([('vc', CountVectorizer()),\n",
    "                          ('tt', TfidfTransformer()),\n",
    "                          ('SDG', SGDClassifier())])\n",
    "\n",
    "        #Set parameters\n",
    "        para = {'vc__ngram_range': ((1, 1), (1, 2)), \n",
    "        'tt__use_idf': (True, False),\n",
    "        }\n",
    "\n",
    "        #Randomized\n",
    "        final_grid = RandomizedSearchCV(final_pipe,para ,n_iter=4,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=0, pre_dispatch='2*n_jobs')\n",
    "        final_grid.fit(combine2[i],y_train.values)\n",
    "        \n",
    "       \n",
    "        #Append\n",
    "        model.append(i)\n",
    "        score[i] = final_grid.best_score_ \n",
    "        para[i] = final_grid.best_params_\n",
    "        print(\"loading done: {} for model: {}\".format((i/len(combine2)*100),(i)))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.932233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.931983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.931733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.931483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.930983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.930983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.930733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.930733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.930483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.929982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.929982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.929982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.929982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.929732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.929732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.929482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.929482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.929482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.929482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.929232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.929232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.929232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.929232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.928982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.928732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.928732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.928732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.928732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.928482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.928482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.927732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.927732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.927732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.927482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.927482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.927482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.927482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.927482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.927482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.926982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.926982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.926732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.926732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.926482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.926482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.926482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.926482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.926232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.926232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.925981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.925981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.925981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.925981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.925231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.924231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score\n",
       "27  0.932233\n",
       "53  0.931983\n",
       "35  0.931733\n",
       "23  0.931483\n",
       "33  0.930983\n",
       "18  0.930983\n",
       "51  0.930733\n",
       "12  0.930733\n",
       "49  0.930483\n",
       "32  0.930233\n",
       "61  0.930233\n",
       "22  0.929982\n",
       "16  0.929982\n",
       "21  0.929982\n",
       "6   0.929982\n",
       "2   0.929732\n",
       "54  0.929732\n",
       "4   0.929482\n",
       "55  0.929482\n",
       "45  0.929482\n",
       "30  0.929482\n",
       "41  0.929232\n",
       "52  0.929232\n",
       "40  0.929232\n",
       "43  0.929232\n",
       "20  0.928982\n",
       "36  0.928732\n",
       "39  0.928732\n",
       "9   0.928732\n",
       "56  0.928732\n",
       "..       ...\n",
       "63  0.928482\n",
       "28  0.928482\n",
       "42  0.928232\n",
       "8   0.928232\n",
       "14  0.927732\n",
       "5   0.927732\n",
       "13  0.927732\n",
       "15  0.927482\n",
       "37  0.927482\n",
       "60  0.927482\n",
       "57  0.927482\n",
       "24  0.927482\n",
       "50  0.927482\n",
       "62  0.926982\n",
       "0   0.926982\n",
       "1   0.926732\n",
       "38  0.926732\n",
       "10  0.926482\n",
       "58  0.926482\n",
       "3   0.926482\n",
       "34  0.926482\n",
       "11  0.926232\n",
       "31  0.926232\n",
       "19  0.925981\n",
       "25  0.925981\n",
       "7   0.925981\n",
       "29  0.925981\n",
       "17  0.925481\n",
       "59  0.925231\n",
       "26  0.924231\n",
       "\n",
       "[64 rows x 1 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the model score\n",
    "score_combine = pd.DataFrame.from_dict({'score':score})\n",
    "score_combine.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done: 0.0 for model: 0\n",
      "loading done: 1.5625 for model: 1\n",
      "loading done: 3.125 for model: 2\n",
      "loading done: 4.6875 for model: 3\n",
      "loading done: 6.25 for model: 4\n",
      "loading done: 7.8125 for model: 5\n",
      "loading done: 9.375 for model: 6\n",
      "loading done: 10.9375 for model: 7\n",
      "loading done: 12.5 for model: 8\n",
      "loading done: 14.0625 for model: 9\n",
      "loading done: 15.625 for model: 10\n",
      "loading done: 17.1875 for model: 11\n",
      "loading done: 18.75 for model: 12\n",
      "loading done: 20.3125 for model: 13\n",
      "loading done: 21.875 for model: 14\n",
      "loading done: 23.4375 for model: 15\n",
      "loading done: 25.0 for model: 16\n",
      "loading done: 26.5625 for model: 17\n",
      "loading done: 28.125 for model: 18\n",
      "loading done: 29.6875 for model: 19\n",
      "loading done: 31.25 for model: 20\n",
      "loading done: 32.8125 for model: 21\n",
      "loading done: 34.375 for model: 22\n",
      "loading done: 35.9375 for model: 23\n",
      "loading done: 37.5 for model: 24\n",
      "loading done: 39.0625 for model: 25\n",
      "loading done: 40.625 for model: 26\n",
      "loading done: 42.1875 for model: 27\n",
      "loading done: 43.75 for model: 28\n",
      "loading done: 45.3125 for model: 29\n",
      "loading done: 46.875 for model: 30\n",
      "loading done: 48.4375 for model: 31\n",
      "loading done: 50.0 for model: 32\n",
      "loading done: 51.5625 for model: 33\n",
      "loading done: 53.125 for model: 34\n",
      "loading done: 54.6875 for model: 35\n",
      "loading done: 56.25 for model: 36\n",
      "loading done: 57.8125 for model: 37\n",
      "loading done: 59.375 for model: 38\n",
      "loading done: 60.9375 for model: 39\n",
      "loading done: 62.5 for model: 40\n",
      "loading done: 64.0625 for model: 41\n",
      "loading done: 65.625 for model: 42\n",
      "loading done: 67.1875 for model: 43\n",
      "loading done: 68.75 for model: 44\n",
      "loading done: 70.3125 for model: 45\n",
      "loading done: 71.875 for model: 46\n",
      "loading done: 73.4375 for model: 47\n",
      "loading done: 75.0 for model: 48\n",
      "loading done: 76.5625 for model: 49\n",
      "loading done: 78.125 for model: 50\n",
      "loading done: 79.6875 for model: 51\n",
      "loading done: 81.25 for model: 52\n",
      "loading done: 82.8125 for model: 53\n",
      "loading done: 84.375 for model: 54\n",
      "loading done: 85.9375 for model: 55\n",
      "loading done: 87.5 for model: 56\n",
      "loading done: 89.0625 for model: 57\n",
      "loading done: 90.625 for model: 58\n",
      "loading done: 92.1875 for model: 59\n",
      "loading done: 93.75 for model: 60\n",
      "loading done: 95.3125 for model: 61\n",
      "loading done: 96.875 for model: 62\n",
      "loading done: 98.4375 for model: 63\n"
     ]
    }
   ],
   "source": [
    "model, score, para = [],{},{}\n",
    "\n",
    "#final_grid = GridSearchCV(final_pipe, para, scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=10, pre_dispatch='2*n_jobs')\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(0,len(combine2)):\n",
    "        #Create a pipeline\n",
    "        final_pipe = Pipeline([('vc', CountVectorizer()),\n",
    "                          ('tt', TfidfTransformer()),\n",
    "                          ('PA', PassiveAggressiveClassifier())])\n",
    "\n",
    "        #Set parameters\n",
    "        para = {'vc__ngram_range': ((1, 1), (1, 2)), \n",
    "        'tt__use_idf': (True, False),\n",
    "        }\n",
    "\n",
    "        #Randomized\n",
    "        final_grid = RandomizedSearchCV(final_pipe,para ,n_iter=4,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=0, pre_dispatch='2*n_jobs')\n",
    "        final_grid.fit(combine2[i],y_train.values)\n",
    "        \n",
    "       \n",
    "        #Append\n",
    "        model.append(i)\n",
    "        score[i] = final_grid.best_score_ \n",
    "        para[i] = final_grid.best_params_\n",
    "        print(\"loading done: {} for model: {}\".format((i/len(combine2)*100),(i)))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.935734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.935734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.935734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.934734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.934734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.934484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.934484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.934484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.934484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.934484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.934234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.934234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.933983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.933983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.933983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.933733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.933733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.933733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.933483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.933483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.933483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.933483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.933483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.933483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.933483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.933483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.933483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.932983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.932983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.932983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.932983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.932983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.932983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.932983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.932983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.932733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.932733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.932733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.932733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.932733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.932483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.932233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.932233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.932233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.931983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.931983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.931983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.931733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.931733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.931483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.931233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.931233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.930983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.930733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.930483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.930483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.930483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score\n",
       "26  0.935734\n",
       "3   0.935734\n",
       "50  0.935734\n",
       "23  0.935484\n",
       "53  0.935484\n",
       "19  0.935484\n",
       "37  0.934734\n",
       "11  0.934734\n",
       "10  0.934484\n",
       "39  0.934484\n",
       "0   0.934484\n",
       "51  0.934484\n",
       "61  0.934484\n",
       "7   0.934234\n",
       "60  0.934234\n",
       "56  0.933983\n",
       "35  0.933983\n",
       "34  0.933983\n",
       "29  0.933733\n",
       "62  0.933733\n",
       "24  0.933733\n",
       "46  0.933483\n",
       "44  0.933483\n",
       "43  0.933483\n",
       "41  0.933483\n",
       "52  0.933483\n",
       "57  0.933483\n",
       "59  0.933483\n",
       "17  0.933483\n",
       "22  0.933483\n",
       "..       ...\n",
       "2   0.932983\n",
       "4   0.932983\n",
       "9   0.932983\n",
       "12  0.932983\n",
       "27  0.932983\n",
       "15  0.932983\n",
       "30  0.932983\n",
       "38  0.932983\n",
       "21  0.932733\n",
       "49  0.932733\n",
       "54  0.932733\n",
       "1   0.932733\n",
       "33  0.932733\n",
       "58  0.932483\n",
       "40  0.932233\n",
       "13  0.932233\n",
       "20  0.932233\n",
       "48  0.931983\n",
       "47  0.931983\n",
       "31  0.931983\n",
       "8   0.931733\n",
       "25  0.931733\n",
       "55  0.931483\n",
       "16  0.931233\n",
       "14  0.931233\n",
       "36  0.930983\n",
       "32  0.930733\n",
       "45  0.930483\n",
       "42  0.930483\n",
       "63  0.930483\n",
       "\n",
       "[64 rows x 1 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the model score\n",
    "score_combine_PA = pd.DataFrame.from_dict({'score':score})\n",
    "score_combine_PA.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done: 0.0 for model: 0\n",
      "loading done: 1.5625 for model: 1\n",
      "loading done: 3.125 for model: 2\n",
      "loading done: 4.6875 for model: 3\n",
      "loading done: 6.25 for model: 4\n",
      "loading done: 7.8125 for model: 5\n",
      "loading done: 9.375 for model: 6\n",
      "loading done: 10.9375 for model: 7\n",
      "loading done: 12.5 for model: 8\n",
      "loading done: 14.0625 for model: 9\n",
      "loading done: 15.625 for model: 10\n",
      "loading done: 17.1875 for model: 11\n",
      "loading done: 18.75 for model: 12\n",
      "loading done: 20.3125 for model: 13\n",
      "loading done: 21.875 for model: 14\n",
      "loading done: 23.4375 for model: 15\n",
      "loading done: 25.0 for model: 16\n",
      "loading done: 26.5625 for model: 17\n",
      "loading done: 28.125 for model: 18\n",
      "loading done: 29.6875 for model: 19\n",
      "loading done: 31.25 for model: 20\n",
      "loading done: 32.8125 for model: 21\n",
      "loading done: 34.375 for model: 22\n",
      "loading done: 35.9375 for model: 23\n",
      "loading done: 37.5 for model: 24\n",
      "loading done: 39.0625 for model: 25\n",
      "loading done: 40.625 for model: 26\n",
      "loading done: 42.1875 for model: 27\n",
      "loading done: 43.75 for model: 28\n",
      "loading done: 45.3125 for model: 29\n",
      "loading done: 46.875 for model: 30\n",
      "loading done: 48.4375 for model: 31\n",
      "loading done: 50.0 for model: 32\n",
      "loading done: 51.5625 for model: 33\n",
      "loading done: 53.125 for model: 34\n",
      "loading done: 54.6875 for model: 35\n",
      "loading done: 56.25 for model: 36\n",
      "loading done: 57.8125 for model: 37\n",
      "loading done: 59.375 for model: 38\n",
      "loading done: 60.9375 for model: 39\n",
      "loading done: 62.5 for model: 40\n",
      "loading done: 64.0625 for model: 41\n",
      "loading done: 65.625 for model: 42\n",
      "loading done: 67.1875 for model: 43\n",
      "loading done: 68.75 for model: 44\n",
      "loading done: 70.3125 for model: 45\n",
      "loading done: 71.875 for model: 46\n",
      "loading done: 73.4375 for model: 47\n",
      "loading done: 75.0 for model: 48\n",
      "loading done: 76.5625 for model: 49\n",
      "loading done: 78.125 for model: 50\n",
      "loading done: 79.6875 for model: 51\n",
      "loading done: 81.25 for model: 52\n",
      "loading done: 82.8125 for model: 53\n",
      "loading done: 84.375 for model: 54\n",
      "loading done: 85.9375 for model: 55\n",
      "loading done: 87.5 for model: 56\n",
      "loading done: 89.0625 for model: 57\n",
      "loading done: 90.625 for model: 58\n",
      "loading done: 92.1875 for model: 59\n",
      "loading done: 93.75 for model: 60\n",
      "loading done: 95.3125 for model: 61\n",
      "loading done: 96.875 for model: 62\n",
      "loading done: 98.4375 for model: 63\n"
     ]
    }
   ],
   "source": [
    "model, score, para = [],{},{}\n",
    "\n",
    "#final_grid = GridSearchCV(final_pipe, para, scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=10, pre_dispatch='2*n_jobs')\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(0,len(combine2)):\n",
    "        #Create a pipeline\n",
    "        final_pipe = Pipeline([('vc', CountVectorizer()),\n",
    "                          ('tt', TfidfTransformer()),\n",
    "                          ('Lsvm', LinearSVC())])\n",
    "\n",
    "        #Set parameters\n",
    "        para = {'vc__ngram_range': ((1, 1), (1, 2)), \n",
    "        'tt__use_idf': (True, False),\n",
    "        }\n",
    "\n",
    "        #Randomized\n",
    "        final_grid = RandomizedSearchCV(final_pipe,para ,n_iter=4,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=0, pre_dispatch='2*n_jobs')\n",
    "        final_grid.fit(combine2[i],y_train.values)\n",
    "        \n",
    "       \n",
    "        #Append\n",
    "        model.append(i)\n",
    "        score[i] = final_grid.best_score_ \n",
    "        para[i] = final_grid.best_params_\n",
    "        print(\"loading done: {} for model: {}\".format((i/len(combine2)*100),(i)))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.931483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.930983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.930733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.930733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.930483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.929982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.929982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.929732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.929732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.929732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.929732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.929482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.929232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.929232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.928982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.928982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.928982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.928982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.928982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.928982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.928982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.928732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.928732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.928732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.928732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.928732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.928482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.928482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.928232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.927982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.927982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.927732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.927732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.927482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.927482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.927232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.926982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.926982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.926982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.926982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.925731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.925731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score\n",
       "34  0.931483\n",
       "18  0.930983\n",
       "50  0.930733\n",
       "2   0.930733\n",
       "10  0.930733\n",
       "36  0.930483\n",
       "58  0.930233\n",
       "42  0.930233\n",
       "27  0.930233\n",
       "43  0.929982\n",
       "59  0.929982\n",
       "23  0.929732\n",
       "21  0.929732\n",
       "19  0.929732\n",
       "26  0.929732\n",
       "52  0.929482\n",
       "53  0.929232\n",
       "55  0.929232\n",
       "49  0.928982\n",
       "48  0.928982\n",
       "35  0.928982\n",
       "39  0.928982\n",
       "22  0.928982\n",
       "37  0.928982\n",
       "51  0.928982\n",
       "38  0.928732\n",
       "33  0.928732\n",
       "32  0.928732\n",
       "20  0.928732\n",
       "11  0.928732\n",
       "..       ...\n",
       "47  0.928482\n",
       "63  0.928482\n",
       "1   0.928232\n",
       "15  0.928232\n",
       "60  0.928232\n",
       "5   0.928232\n",
       "57  0.928232\n",
       "56  0.928232\n",
       "7   0.928232\n",
       "8   0.928232\n",
       "9   0.928232\n",
       "13  0.928232\n",
       "0   0.928232\n",
       "28  0.928232\n",
       "41  0.928232\n",
       "44  0.928232\n",
       "40  0.928232\n",
       "31  0.927982\n",
       "29  0.927982\n",
       "46  0.927732\n",
       "62  0.927732\n",
       "17  0.927482\n",
       "16  0.927482\n",
       "30  0.927232\n",
       "25  0.926982\n",
       "12  0.926982\n",
       "4   0.926982\n",
       "24  0.926982\n",
       "6   0.925731\n",
       "14  0.925731\n",
       "\n",
       "[64 rows x 1 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the model score\n",
    "score_combine_LSVM = pd.DataFrame.from_dict({'score':score})\n",
    "score_combine_LSVM.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done: 0.0 for model: 0\n",
      "loading done: 1.5625 for model: 1\n",
      "loading done: 3.125 for model: 2\n",
      "loading done: 4.6875 for model: 3\n",
      "loading done: 6.25 for model: 4\n",
      "loading done: 7.8125 for model: 5\n",
      "loading done: 9.375 for model: 6\n",
      "loading done: 10.9375 for model: 7\n",
      "loading done: 12.5 for model: 8\n",
      "loading done: 14.0625 for model: 9\n",
      "loading done: 15.625 for model: 10\n",
      "loading done: 17.1875 for model: 11\n",
      "loading done: 18.75 for model: 12\n",
      "loading done: 20.3125 for model: 13\n",
      "loading done: 21.875 for model: 14\n",
      "loading done: 23.4375 for model: 15\n",
      "loading done: 25.0 for model: 16\n",
      "loading done: 26.5625 for model: 17\n",
      "loading done: 28.125 for model: 18\n",
      "loading done: 29.6875 for model: 19\n",
      "loading done: 31.25 for model: 20\n",
      "loading done: 32.8125 for model: 21\n",
      "loading done: 34.375 for model: 22\n",
      "loading done: 35.9375 for model: 23\n",
      "loading done: 37.5 for model: 24\n",
      "loading done: 39.0625 for model: 25\n",
      "loading done: 40.625 for model: 26\n",
      "loading done: 42.1875 for model: 27\n",
      "loading done: 43.75 for model: 28\n",
      "loading done: 45.3125 for model: 29\n",
      "loading done: 46.875 for model: 30\n",
      "loading done: 48.4375 for model: 31\n",
      "loading done: 50.0 for model: 32\n",
      "loading done: 51.5625 for model: 33\n",
      "loading done: 53.125 for model: 34\n",
      "loading done: 54.6875 for model: 35\n",
      "loading done: 56.25 for model: 36\n",
      "loading done: 57.8125 for model: 37\n",
      "loading done: 59.375 for model: 38\n",
      "loading done: 60.9375 for model: 39\n",
      "loading done: 62.5 for model: 40\n",
      "loading done: 64.0625 for model: 41\n",
      "loading done: 65.625 for model: 42\n",
      "loading done: 67.1875 for model: 43\n",
      "loading done: 68.75 for model: 44\n",
      "loading done: 70.3125 for model: 45\n",
      "loading done: 71.875 for model: 46\n",
      "loading done: 73.4375 for model: 47\n",
      "loading done: 75.0 for model: 48\n",
      "loading done: 76.5625 for model: 49\n",
      "loading done: 78.125 for model: 50\n",
      "loading done: 79.6875 for model: 51\n",
      "loading done: 81.25 for model: 52\n",
      "loading done: 82.8125 for model: 53\n",
      "loading done: 84.375 for model: 54\n",
      "loading done: 85.9375 for model: 55\n",
      "loading done: 87.5 for model: 56\n",
      "loading done: 89.0625 for model: 57\n",
      "loading done: 90.625 for model: 58\n",
      "loading done: 92.1875 for model: 59\n",
      "loading done: 93.75 for model: 60\n",
      "loading done: 95.3125 for model: 61\n",
      "loading done: 96.875 for model: 62\n",
      "loading done: 98.4375 for model: 63\n"
     ]
    }
   ],
   "source": [
    "model, score, para = [],{},{}\n",
    "\n",
    "#final_grid = GridSearchCV(final_pipe, para, scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=10, pre_dispatch='2*n_jobs')\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(0,len(combine2)):\n",
    "        #Create a pipeline\n",
    "        final_pipe = Pipeline([('vc', CountVectorizer()),\n",
    "                          ('tt', TfidfTransformer()),\n",
    "                          ('LG', LogisticRegression())])\n",
    "\n",
    "        #Set parameters\n",
    "        para = {'vc__ngram_range': ((1, 1), (1, 2)), \n",
    "        'tt__use_idf': (True, False),\n",
    "        }\n",
    "\n",
    "        #Randomized\n",
    "        final_grid = RandomizedSearchCV(final_pipe,para ,n_iter=4,scoring='accuracy', fit_params=None, n_jobs=2, iid=True, refit=True, cv=kfold, verbose=0, pre_dispatch='2*n_jobs')\n",
    "        final_grid.fit(combine2[i],y_train.values)\n",
    "        \n",
    "       \n",
    "        #Append\n",
    "        model.append(i)\n",
    "        score[i] = final_grid.best_score_ \n",
    "        para[i] = final_grid.best_params_\n",
    "        print(\"loading done: {} for model: {}\".format((i/len(combine2)*100),(i)))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.907477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.907477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.907477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.907477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.907227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.907227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.906727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.906727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.906727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.906727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.906727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.906727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.906477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.906227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.906227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.905976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.905976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.905976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.905976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.905976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.905976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.905976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.905726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.905726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.905726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.905726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.905726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.905726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.905726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.905726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.905476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.905476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.905226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.905226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.905226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.904476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.904476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.904476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.904476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.904476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.904226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.904226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.903976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.903976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.902476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.902476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.902476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.902226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.902226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.901975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.901725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.901725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.901475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.901475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.901475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.901225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.900725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.900725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score\n",
       "32  0.907477\n",
       "49  0.907477\n",
       "48  0.907477\n",
       "33  0.907477\n",
       "29  0.907227\n",
       "31  0.907227\n",
       "61  0.906727\n",
       "52  0.906727\n",
       "47  0.906727\n",
       "45  0.906727\n",
       "36  0.906727\n",
       "63  0.906727\n",
       "20  0.906477\n",
       "23  0.906227\n",
       "21  0.906227\n",
       "12  0.905976\n",
       "4   0.905976\n",
       "6   0.905976\n",
       "38  0.905976\n",
       "14  0.905976\n",
       "17  0.905976\n",
       "16  0.905976\n",
       "0   0.905726\n",
       "39  0.905726\n",
       "13  0.905726\n",
       "37  0.905726\n",
       "8   0.905726\n",
       "15  0.905726\n",
       "5   0.905726\n",
       "9   0.905726\n",
       "..       ...\n",
       "53  0.905476\n",
       "55  0.905476\n",
       "44  0.905226\n",
       "60  0.905226\n",
       "30  0.905226\n",
       "56  0.904476\n",
       "57  0.904476\n",
       "41  0.904476\n",
       "40  0.904476\n",
       "28  0.904476\n",
       "62  0.904226\n",
       "46  0.904226\n",
       "24  0.903976\n",
       "25  0.903976\n",
       "59  0.903226\n",
       "43  0.903226\n",
       "35  0.902476\n",
       "51  0.902476\n",
       "26  0.902476\n",
       "19  0.902226\n",
       "27  0.902226\n",
       "50  0.901975\n",
       "2   0.901725\n",
       "10  0.901725\n",
       "42  0.901475\n",
       "58  0.901475\n",
       "18  0.901475\n",
       "34  0.901225\n",
       "3   0.900725\n",
       "11  0.900725\n",
       "\n",
       "[64 rows x 1 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the model score\n",
    "score_combine_LG = pd.DataFrame.from_dict({'score':score})\n",
    "score_combine_LG.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t0t1-tt0tt1',\n",
       " 't0t1-tt0tt2',\n",
       " 't0t1-tt0tt3',\n",
       " 't0t1-tt0tt4',\n",
       " 't0t1-tt0tt1tt3',\n",
       " 't0t1-tt0tt1tt4',\n",
       " 't0t1-tt0tt2tt3',\n",
       " 't0t1-tt0tt2tt4',\n",
       " 't0t2-tt0tt1',\n",
       " 't0t2-tt0tt2',\n",
       " 't0t2-tt0tt3',\n",
       " 't0t2-tt0tt4',\n",
       " 't0t2-tt0tt1tt3',\n",
       " 't0t2-tt0tt1tt4',\n",
       " 't0t2-tt0tt2tt3',\n",
       " 't0t2-tt0tt2tt4',\n",
       " 't0t3-tt0tt1',\n",
       " 't0t3-tt0tt2',\n",
       " 't0t3-tt0tt3',\n",
       " 't0t3-tt0tt4',\n",
       " 't0t3-tt0tt1tt3',\n",
       " 't0t3-tt0tt1tt4',\n",
       " 't0t3-tt0tt2tt3',\n",
       " 't0t3-tt0tt2tt4',\n",
       " 't0t4-tt0tt1',\n",
       " 't0t4-tt0tt2',\n",
       " 't0t4-tt0tt3',\n",
       " 't0t4-tt0tt4',\n",
       " 't0t4-tt0tt1tt3',\n",
       " 't0t4-tt0tt1tt4',\n",
       " 't0t4-tt0tt2tt3',\n",
       " 't0t4-tt0tt2tt4',\n",
       " 't0t1t3-tt0tt1',\n",
       " 't0t1t3-tt0tt2',\n",
       " 't0t1t3-tt0tt3',\n",
       " 't0t1t3-tt0tt4',\n",
       " 't0t1t3-tt0tt1tt3',\n",
       " 't0t1t3-tt0tt1tt4',\n",
       " 't0t1t3-tt0tt2tt3',\n",
       " 't0t1t3-tt0tt2tt4',\n",
       " 't0t1t4-tt0tt1',\n",
       " 't0t1t4-tt0tt2',\n",
       " 't0t1t4-tt0tt3',\n",
       " 't0t1t4-tt0tt4',\n",
       " 't0t1t4-tt0tt1tt3',\n",
       " 't0t1t4-tt0tt1tt4',\n",
       " 't0t1t4-tt0tt2tt3',\n",
       " 't0t1t4-tt0tt2tt4',\n",
       " 't0t2t3-tt0tt1',\n",
       " 't0t2t3-tt0tt2',\n",
       " 't0t2t3-tt0tt3',\n",
       " 't0t2t3-tt0tt4',\n",
       " 't0t2t3-tt0tt1tt3',\n",
       " 't0t2t3-tt0tt1tt4',\n",
       " 't0t2t3-tt0tt2tt3',\n",
       " 't0t2t3-tt0tt2tt4',\n",
       " 't0t2t4-tt0tt1',\n",
       " 't0t2t4-tt0tt2',\n",
       " 't0t2t4-tt0tt3',\n",
       " 't0t2t4-tt0tt4',\n",
       " 't0t2t4-tt0tt1tt3',\n",
       " 't0t2t4-tt0tt1tt4',\n",
       " 't0t2t4-tt0tt2tt3',\n",
       " 't0t2t4-tt0tt2tt4']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i + \"-\" +j for i in title_rework for j in text_reword]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
