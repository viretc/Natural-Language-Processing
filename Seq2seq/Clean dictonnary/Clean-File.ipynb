{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaner\n",
    "\n",
    "\n",
    "Code to clean (the French – English words) and pair the txt file. For example, it removes the upper case or some of the punctuation of specific characters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "from unicodedata import normalize\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## function ##\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in  lines]\n",
    "    return pairs\n",
    "\n",
    "def clean_file(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    string_print = ' a-zA-ZàâäôéèëêïîçùûüÿæœÀÂÄÔÉÈËÊÏÎŸÇÙÛÜÆŒ0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'\n",
    "    re_print = re.compile('[^%s]' % re.escape(string_print))\n",
    "    string_punc = '!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_{|}~'\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string_punc)\n",
    "    for pair in lines:\n",
    "        clean_pairs = list()\n",
    "        for line in pair:\n",
    "            line = normalize('NFKD', line).encode('latin1', 'ignore')\n",
    "            line = line.decode('latin1')\n",
    "            # tokenize on white space\n",
    "            line = line.split()\n",
    "            # convert to lowercase\n",
    "            line = [word.lower() for word in line]\n",
    "            # remove punctuation from each token\n",
    "            line = [word.translate(table) for word in line]\n",
    "            # remove non-printable chars form each token\n",
    "            line = [re_print.sub('', w) for w in line]\n",
    "            # remove tokens with numbers in them\n",
    "        #    line = [word for word in line if word.isalpha()]\n",
    "            # store as string\n",
    "            clean_pairs.append(\" \".join(line))\n",
    "        cleaned.append(clean_pairs)\n",
    "    return array(cleaned)\n",
    "\n",
    "\n",
    "# save a list of clean sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english-french_final.pkl\n",
      "[dogs] => [chiens]\n",
      "[i love dogs] => [j'aime les chiens]\n",
      "[cats] => [chats]\n",
      "[basketball] => [basketball]\n",
      "[i like football and baseball] => [j'aime le football et le baseball]\n",
      "[football] => [football]\n",
      "[my favorite sport is football] => [mon sport favori est le football]\n",
      "[baseball is the best sprot] => [le baseball c'est le meilleur sport]\n",
      "[baseball] => [baseball]\n",
      "[apples] => [pommes]\n",
      "[i like a lot apples] => [j'aime beaucoup les pommes]\n",
      "[go] => [va ]\n",
      "[run] => [cours ]\n",
      "[run] => [courez ]\n",
      "[fire] => [au feu ]\n",
      "[help] => [a l'aide ]\n",
      "[jump] => [saute]\n",
      "[stop] => [ca suffit ]\n",
      "[stop] => [stop ]\n",
      "[stop] => [arretetoi ]\n",
      "[wait] => [attends ]\n",
      "[wait] => [attendez ]\n",
      "[go on] => [poursuis]\n",
      "[go on] => [continuez]\n",
      "[go on] => [poursuivez]\n",
      "[i see] => [je comprends]\n",
      "[i try] => [j'essaye]\n",
      "[i won] => [j'ai gagne ]\n",
      "[i won] => [je l'ai emporte ]\n",
      "[oh no] => [oh non ]\n",
      "[attack] => [attaque ]\n",
      "[attack] => [attaquez ]\n",
      "[cheers] => [sante ]\n",
      "[cheers] => [a votre sante ]\n",
      "[cheers] => [merci ]\n",
      "[cheers] => [tchintchin ]\n",
      "[get up] => [levetoi]\n",
      "[go now] => [va maintenant]\n",
      "[go now] => [allezy maintenant]\n",
      "[go now] => [vasy maintenant]\n",
      "[got it] => [j'ai pige ]\n",
      "[got it] => [compris ]\n",
      "[got it] => [pige ]\n",
      "[got it] => [compris ]\n",
      "[got it] => [t'as capte ]\n",
      "[hop in] => [monte]\n",
      "[hop in] => [montez]\n",
      "[hug me] => [serremoi dans tes bras ]\n",
      "[hug me] => [serrezmoi dans vos bras ]\n",
      "[i fell] => [je suis tombee]\n",
      "[i fell] => [je suis tombe]\n",
      "[i know] => [je sais]\n",
      "[i left] => [je suis parti]\n",
      "[i left] => [je suis partie]\n",
      "[i lost] => [j'ai perdu]\n",
      "[i'm 19] => [j'ai 19 ans]\n",
      "[i'm ok] => [je vais bien]\n",
      "[i'm ok] => [ca va]\n",
      "[listen] => [ecoutez ]\n",
      "[no way] => [c'est pas possible ]\n",
      "[no way] => [impossible ]\n",
      "[no way] => [en aucun cas]\n",
      "[no way] => [sans facons ]\n",
      "[no way] => [c'est hors de question ]\n",
      "[no way] => [il n'en est pas question ]\n",
      "[no way] => [c'est exclu ]\n",
      "[no way] => [en aucune maniere ]\n",
      "[no way] => [hors de question ]\n",
      "[really] => [vraiment ]\n",
      "[really] => [vrai ]\n",
      "[really] => [ah bon ]\n",
      "[thanks] => [merci ]\n",
      "[we try] => [on essaye]\n",
      "[we won] => [nous avons gagne]\n",
      "[we won] => [nous gagnames]\n",
      "[we won] => [nous l'avons emporte]\n",
      "[we won] => [nous l'emportames]\n",
      "[ask tom] => [demande a tom]\n",
      "[awesome] => [fantastique ]\n",
      "[be calm] => [sois calme ]\n",
      "[be calm] => [soyez calme ]\n",
      "[be calm] => [soyez calmes ]\n",
      "[be cool] => [sois detendu ]\n",
      "[be fair] => [sois juste ]\n",
      "[be fair] => [soyez juste ]\n",
      "[be fair] => [soyez justes ]\n",
      "[be fair] => [sois equitable ]\n",
      "[be fair] => [soyez equitable ]\n",
      "[be fair] => [soyez equitables ]\n",
      "[be kind] => [sois gentil]\n",
      "[be nice] => [sois gentil ]\n",
      "[be nice] => [sois gentille ]\n",
      "[be nice] => [soyez gentil ]\n",
      "[be nice] => [soyez gentille ]\n",
      "[be nice] => [soyez gentils ]\n",
      "[be nice] => [soyez gentilles ]\n",
      "[beat it] => [degage ]\n",
      "[call me] => [appellemoi ]\n",
      "[call me] => [appellezmoi ]\n",
      "[call us] => [appellenous ]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "filename = 'fra.txt'\n",
    "doc = load_doc(filename)\n",
    "# split into english and french pairs\n",
    "pairs = to_pairs(doc)\n",
    "\n",
    "#adding vocabulary\n",
    "text = [[\"dogs\",\"chiens\"],\n",
    "        [\"I love dogs\",\"j'aime les chiens\"],\n",
    "        ['cats',\"chats\"],\n",
    "        [\"basketball\",\"basketball\"],\n",
    "        [\"I like football and baseball\",\"j'aime le football et le baseball\"],\n",
    "        ['football',\"football\"],\n",
    "        [\"my favorite sport is football\", \"mon sport favori est le football\"],\n",
    "        [\"baseball is the best sprot\",\"le baseball c'est le meilleur sport\"],\n",
    "        ['baseball','baseball'],\n",
    "        [\"apples\",\"pommes\"],\n",
    "        [\"I like a lot apples\",\"j'aime beaucoup les pommes\"]\n",
    "               ]\n",
    "\n",
    "text.extend(pairs)\n",
    "#get pairs\n",
    "clean_pairs = clean_file(text)\n",
    "# save clean pairs to file\n",
    "save_clean_data(clean_pairs, 'english-french_final.pkl')\n",
    "\n",
    "for i in range(100):\n",
    "    print('[%s] => [%s]' % (clean_pairs[i,0], clean_pairs[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
